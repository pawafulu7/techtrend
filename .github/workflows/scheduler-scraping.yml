name: Scheduler - Scraping Twice Daily

on:
  schedule:
    - cron: '0 15 * * *' # JST 00:00
    - cron: '0 3 * * *'  # JST 12:00
  workflow_dispatch:

concurrency:
  group: techtrend-scheduler
  cancel-in-progress: false

jobs:
  scraping:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
      - name: Install deps
        run: npm ci
      - name: Generate Prisma Client
        run: npx prisma generate
      - name: Apply DB migrations
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: npx prisma migrate deploy
      - name: Collect scraping sources and post-process
        env:
          NODE_ENV: production
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          REDIS_URL: ${{ secrets.REDIS_URL }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          npx tsx scripts/scheduled/collect-feeds.ts "Speaker Deck" "Docswell"
          npx tsx scripts/scheduled/manage-summaries.ts generate
          npx tsx scripts/scheduled/manage-quality-scores.ts calculate
          npx tsx scripts/scheduled/calculate-difficulty-levels.ts
