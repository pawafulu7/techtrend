#!/usr/bin/env tsx
import fetch from 'node-fetch';

async function testLocalLLM() {
  console.log('ğŸ§ª ãƒ­ãƒ¼ã‚«ãƒ«LLMæ¥ç¶šãƒ†ã‚¹ãƒˆ\n');
  
  const url = process.env.LOCAL_LLM_URL || 'http://192.168.11.7:1234';
  
  console.log(`URL: ${url}`);
  console.log('ç’°å¢ƒå¤‰æ•° LOCAL_LLM_URL:', process.env.LOCAL_LLM_URL);
  console.log('ç’°å¢ƒå¤‰æ•° LOCAL_LLM_MODEL:', process.env.LOCAL_LLM_MODEL);
  console.log('ç’°å¢ƒå¤‰æ•° USE_LOCAL_LLM_FALLBACK:', process.env.USE_LOCAL_LLM_FALLBACK);
  console.log();
  
  // 1. ãƒ¢ãƒ‡ãƒ«ä¸€è¦§å–å¾—ãƒ†ã‚¹ãƒˆ
  console.log('ğŸ“¡ ãƒ¢ãƒ‡ãƒ«ä¸€è¦§å–å¾—ãƒ†ã‚¹ãƒˆ...');
  try {
    const response = await fetch(`${url}/v1/models`, {
      method: 'GET',
      headers: {
        'Content-Type': 'application/json',
      },
    });
    
    console.log('Status:', response.status);
    console.log('OK:', response.ok);
    
    if (response.ok) {
      const data = await response.json();
      console.log('ãƒ¢ãƒ‡ãƒ«æ•°:', data.data?.length || 0);
      if (data.data && data.data.length > 0) {
        console.log('åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«:');
        data.data.forEach((model: any) => {
          console.log(`  - ${model.id}`);
        });
      }
    }
  } catch (error) {
    console.error('âŒ ã‚¨ãƒ©ãƒ¼:', error);
  }
  
  console.log();
  
  // 2. ãƒãƒ£ãƒƒãƒˆè£œå®Œãƒ†ã‚¹ãƒˆ
  console.log('ğŸ’¬ ãƒãƒ£ãƒƒãƒˆè£œå®Œãƒ†ã‚¹ãƒˆ...');
  try {
    const response = await fetch(`${url}/v1/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'openai/gpt-oss-20b',
        messages: [
          {
            role: 'user',
            content: 'Hello, please respond with "Hi there!" only.'
          }
        ],
        max_tokens: 10,
        temperature: 0.1,
      }),
    });
    
    console.log('Status:', response.status);
    
    if (response.ok) {
      const data = await response.json();
      console.log('âœ… å¿œç­”:', data.choices?.[0]?.message?.content);
    } else {
      console.log('âŒ ã‚¨ãƒ©ãƒ¼:', await response.text());
    }
  } catch (error) {
    console.error('âŒ ã‚¨ãƒ©ãƒ¼:', error);
  }
}

testLocalLLM().catch(console.error);