id,title,url,summary,thumbnail,content,publishedAt,sourceId,bookmarks,qualityScore,userVotes,createdAt,updatedAt,difficulty,detailedSummary,articleType,summaryVersion
cmelaopf2000nteaepo6aspqw,AI Mode in Search gets new agentic features and expands globally,https://blog.google/products/search/ai-mode-agentic-personalized/,Google検索のAIモードがグローバル展開し、新機能を追加しました。より高度な情報検索と対話型体験を提供することで、ユーザーエクスペリエンスを向上させます。このアップデートは、AIを活用した検索の進化を示す重要なステップです。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Expanding_AI_mode.max-600x600.format-webp.webp,"<img src=""https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Expanding_AI_mode.max-600x600.format-webp.webp"">AI Mode in Google Search is expanding to more regions and adding more features.",2025-08-21 11:00:00,cmdwmplco0001tec833nye4ak,0,75,0,2025-08-21 11:05:01.358,2025-08-22 05:06:36.737,,"・グローバル展開：AIモードは、これまで限定的な地域でのみ利用可能でしたが、今回のアップデートにより、世界中の多くの地域で利用可能になります。これにより、より多くのユーザーがAIを活用した高度な検索機能を利用できるようになります。具体的な地域や展開スケジュールはGoogle公式発表を参照ください。
・新機能追加：今回のアップデートでは、AIモードに新たな機能が追加されました。具体的な機能内容はGoogle公式発表に詳細が記載されていますが、ユーザーとの対話性を高める「agentic features」が含まれていると推測されます。これにより、より自然で直感的な検索体験が可能になります。
・ユーザーエクスペリエンスの向上：AIモードのグローバル展開と新機能追加は、ユーザーエクスペリエンスの向上に大きく貢献します。より高度な情報検索、より自然な対話型検索体験を提供することで、ユーザーはより効率的かつ効果的に情報を取得できるようになります。この改善は、検索エンジンの進化における重要なマイルストーンと言えるでしょう。",unified,8
cmdwms0ek004bte68r4ljg6l2,The latest AI news we announced in June,https://blog.google/technology/ai/google-ai-updates-june-2025/,Googleは6月のAI関連発表をまとめた。Gemini 2.5 Flash-Lite、Gemini CLI(オープンソースAIエージェント)、Imagen 4(テキストから画像生成モデル)などを発表、一般公開またはプレビュー提供を開始した。AI Modeの機能強化(音声検索、インタラクティブチャート)やGoogle Photosの「Ask Photos」改善、AI搭載Chromebookの発売、教育向けGemini、ゲノム解析AI AlphaGenome、AIを活用したハリケーン予測システムWeather Labなども発表、AIの医療応用への取り組みも示された。これらの発表は、AIが様々な分野で活用され、社会に貢献していく可能性を示している。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/June_AI_Recap_social-share.width-1300.png,"For more than 20 years, we’ve invested in machine learning and AI research, tools and infrastructure to build products that make everyday life better for more people. Teams across Google are working on ways to unlock AI’s benefits in fields as wide-ranging as healthcare, crisis response and education. To keep you posted on our progress, we're doing a regular roundup of Google's most recent AI news.Here’s a look back at some of our AI announcements from June.June marked the mid-year solstice — the halfway point for Earth's revolution around the sun. What better opportunity for us to talk about the latest ways that Google AI is revolutionizing (ahem) the way people build and create, learn, search for information and even make scientific breakthroughs?We expanded our Gemini 2.5 family of models. Along with making Gemini 2.5 Flash and Pro generally available for everyone, we introduced 2.5 Flash-Lite, our most cost-efficient and fastest 2.5 model yet.We introduced Gemini CLI, an open-source AI agent for developers. Gemini CLI brings Gemini directly into your terminal for coding, problem-solving and task management. You can access Gemini 2.5 Pro free of charge with a personal Google account, or use a Google AI Studio or Vertex AI key for more access.We released Imagen 4 for developers in the Gemini API and Google AI Studio. Imagen 4, our best text-to-image model yet, is now available for paid preview in the Gemini API and for limited free testing in Google AI Studio. Imagen 4 offers significantly improved text rendering over our prior image models and will be generally available in the coming weeks.We shared a closer look inside AI Mode. AI Mode is our most powerful AI search, and this month we shared how we brought it to life (and your fingertips) in a look at the history of its development.We introduced a new way to search with your voice in AI Mode. Search Live with voice lets you talk, listen and explore in real time with AI Mode in the Google app for Android and iOS. That means you can now have free-flowing, back-and-forth voice conversations with Search and explore links from across the web, so you can multitask and do things like find real-time tips for a trip while you’re packing for it. And with helpful transcripts saved in your AI Mode history, you can always revisit your searches and dive deeper on the web.We released interactive charts in AI Mode for financial data, stocks and mutual funds. With interactive chart visualizations in AI Mode, you can compare and analyze information over a specific time period, get an interactive graph and comprehensive explanations to your question, and ask follow-ups, thanks to our custom Gemini model’s advanced multi-step reasoning and multimodal capabilities in AI Mode.We improved Ask Photos and brought it to more Google Photos users. Ask Photos uses Gemini models to help you find your photos with complex queries like “what did I eat on my trip to Barcelona?” At the same time, it now returns more photos faster for simpler searches like “beach” or “dogs.”We released our most advanced Chromebook Plus yet, with new helpful AI features. The new Lenovo Chromebook Plus 14 launched with several AI features to help you get things done — like Smart grouping to organize your open tabs and documents, AI image editing in the Gallery app, and the ability to take text from images and turn it into editable text. (Plus, it comes with custom wallpapers of Jupiter, created using generative AI in partnership with NASA especially for the Lenovo Chromebook Plus 14.)We created a new way to share your NotebookLM notebooks publicly. Now, you can share a notebook publicly with anyone using NotebookLM with a single link, whether it’s an overview of your nonprofit’s projects, product manuals for your business or study guides for your class.We introduced Gemini for Education to help students and educators. Gemini for Education is a version of the Gemini app built for the unique needs of the educational community. And at this year’s International Society for Technology in Education (ISTE) conference, we shared how this new AI solution could help every learner and educator, from personalizing learning for students to helping teachers generate compelling content, and more.We introduced AlphaGenome: AI to better understand the human genome. Our new, unifying DNA sequence model advances regulatory variant-effect prediction and promises to shed new light on genome function. To advance scientific research, we’re making AlphaGenome available in preview via our AlphaGenome API for non-commercial research, with plans to release the model in the future.We launched Weather Lab to support better tropical cyclone prediction with AI. Google DeepMind and Google Research’s Weather Lab is an interactive website for sharing our AI weather models. Weather Lab features our experimental cyclone predictions, and we’re partnering with the U.S. National Hurricane Center to support their forecasts and warnings this cyclone season.We shared how AI breakthroughs are bringing hope to cancer research and treatment. Our President and Chief Investment Officer, Ruth Porat, spoke to the American Society of Clinical Oncology and discussed how Google’s AI research shows promise for early detection and treatment of cancer.We introduced Gemini Robotics On-Device to bring AI to robots. In March, we shared how Gemini Robotics, our most advanced VLA (vision language action) model, brings multimodal reasoning and real-world understanding to machines in the physical world. Gemini Robotics On-Device is the next step. It shows how to equip robots with strong general-purpose dexterity and task generalization and is optimized to run efficiently on the robot itself. We also shared how Gemini 2.5 can enhance robotics and embodied intelligence.",2025-07-02 16:00:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-04 04:49:16.556,2025-08-22 05:06:36.9,intermediate,"・Gemini 2.5ファミリーの拡張：6月には、Gemini 2.5 FlashとProの一般公開に加え、コスト効率と速度を重視したGemini 2.5 Flash-Liteを発表した。これは、GoogleのAIモデルの幅広いニーズへの対応を示している。開発者向けには、ターミナルからGeminiに直接アクセスできるオープンソースAIエージェントGemini CLIも提供開始された。個人アカウント、Google AI Studio、Vertex AIキーで利用可能だ
・Imagen 4のリリース：テキストから画像を生成するモデルImagen 4が、Gemini APIとGoogle AI Studioで開発者向けにリリースされた。先行モデルよりテキストレンダリングが大幅に向上しており、今後数週間で一般公開予定である。これは、高品質な画像生成技術の進歩を示す
・AI Modeの機能強化：AI Modeは、Google検索における強力なAI検索機能だが、その開発の歴史が公開された。音声検索機能「Search Live with voice」がAndroidとiOSのGoogleアプリに追加され、リアルタイムでの音声対話による検索が可能になった。また、金融データ、株価、投資信託向けのインタラクティブチャートも追加された。これは、検索体験の向上と情報アクセスの容易化を示す
・Google Photosの「Ask Photos」改善：Geminiモデルを活用した「Ask Photos」は、複雑な検索クエリにも対応できるようになった。例えば、「バルセロナ旅行で何を食べたか」といった質問にも対応可能で、シンプルな検索クエリに対する応答速度も向上した。これは、画像検索の精度と効率の向上を示す
・AI搭載Chromebook Plusとその他の発表：AI機能を搭載した新しいLenovo Chromebook Plus 14を発表した。Smart grouping、AI画像編集機能、画像テキスト抽出機能などが搭載されている。その他、NotebookLMノートブックの公開共有機能、教育機関向けのGemini for Education、ゲノム解析AI AlphaGenome、AIを活用したハリケーン予測システムWeather Lab、医療分野におけるAI活用など、幅広い分野でのAI技術の応用が発表された。これらの発表は、AI技術の多様な応用と社会への貢献を示している",unified,8
cmdwmrzy3000wte680kxfnjt1,Can AI save nurses millions of hours of paperwork?,https://blog.google/products/google-cloud/hca-healthcare-nurse-handoff-app/,"HCAヘルスケアは、Google Cloudと協力し、看護師の業務効率化を目的としたAI搭載アプリ「Nurse Handoff」を開発した。年間1000万時間にも及ぶ看護師の事務作業（患者情報引き継ぎ）を削減し、患者ケアの質向上と安全性の確保を目指す。現在5病院でパイロット運用中で、99,000人の看護師への展開を計画している。初期テストでは、情報の正確性86%、有用性90%と高い評価を得ている。",https://storage.googleapis.com/gweb-uniblog-publish-prod/images/nurse_handoff_ss.width-1300.png,"Breadcrumb Products Google Cloud Can AI save nurses millions of hours of paperwork? Jul 29, 2025 · Share Twitter Facebook LinkedIn Mail Copy link At HCA Healthcare, thousands of nurses spend as much as 10 million hours a year on paperwork and communications for their daily patient handoffs. What if AI could help save them some of this time — and help save more lives in the process? Matt A.V. Chaban Keyword Contributor Share Twitter Facebook LinkedIn Mail Copy link Each day, across HCA Healthcare’s 190 hospitals and approximately 2,400 ambulatory sites of care, nurses repeat the same task around 60,000 times: passing patient-specific information from one nurse to another during shift change to help ensure care continuity and safety.It’s an everyday task that’s anything but routine. The notes are a main part of the patient handoff that happens when nurses change shifts every 12 hours. Nurse handoffs are a crucial step to ensure uninterrupted care between provider teams, as one nurse passes along their carefully collected information to the next. Patient safety requires timely and relevant handoff communication, making these records much more than simple paperwork.“Depending on the types of patients and which nurses are giving the report, you could end up with a pretty big stack of papers,” explains Samantha Hall, a registered nurse at TriStar Hendersonville Medical Center, an HCA Healthcare hospital in Tennessee.It’s such an important and complex challenge that when HCA Healthcare began exploring how it might bring generative AI into its operations, the patient handoff was one of the first opportunities it decided to pursue.Over the course of 2024, HCA Healthcare’s Digital Transformation and Innovation (DT&I) department worked with Google Cloud’s healthcare solutions team to build and optimize a new AI-powered app, called Nurse Handoff.“Nurse handoff communication is critical to any hospital and is fundamental to the role of registered nurses for safely exchanging communication and care about a patient,” said Dr. Whitney Staub-Juergens, vice president of transformation operations at HCA Healthcare. “It’s how they fundamentally get organized for the next 12 hours.”Nurse Handoff is designed to collect and organize patient notes digitally, for easier reference and accuracy. The hope is, it can help nurses prep for their shift in a whole new way, giving them back time to reinvest with their patients.Millions of hours investedIf Nurse Handoff could have even a small impact on how handoffs happen, nurses could claim back some of the 10 million hours that HCA Healthcare estimates they collectively spend each year on these paper-based tasks. More time with patients, as well as any increase in accuracy, or new insights from analytics, should lead to better health outcomes.And since HCA Healthcare is the largest hospital provider in the U.S., both by number of hospitals and number of beds, any success it has would be likely to spread across the industry. Given the care complexities medical teams can face day to day, Nurse Handoff was designed to be as simple and straightforward as its name.The team developed a tool, named Nurse Handoff, that shows nurses the electronic health record on one side and the AI-generated output on the other. Using a hospital-provided mobile device, nurses are able to easily review and add information throughout their shift. Google’s MedLM models, running within the Nurse Handoff app, can ingest, analyze, and develop a cohesive and concise view of pertinent patient information for the oncoming nurse for handoff.Traditionally, nurses rely upon their recollection of events, conversations, and data points, leaving room for error and inconsistency in the information given during handoff. Using Nurse Handoff during their shift, nurses can easily find the information they and their peers have collected through the automated shift report and add their own notes, so the system keeps building. This can include relevant patient data from notes, orders, tests, and more. All this happens within a highly secure cloud environment, to keep patient information confidential.HCA Healthcare is currently piloting Nurse Handoff in five of its hospitals, gathering feedback and continuing to fine tune both its AI model and the user experience.Nurses’ ordersAn important part of building an effective app that frontline nurses would want to use was working directly with them on its development. That included K.C. DeShetler, a registered nurse on the HCA Healthcare DT&I team who became product owner for Nurse Handoff.“We fed our model the information nurses want to know, prompted the model in a multitude of ways, used retrieval augmented generation to identify citations for the generated content, provided templates for organizing information the way we want and so forth,” DeShelter explains.The approach they settled on shows nurses a familiar electronic health record on one side of the screen and an AI-generated output on the other. Hall, the nurse from Tennessee, was among a group of early testers who reviewed the model’s output to highlight what was unnecessary, repetitive, inaccurate or missing.“We went through that process three or four different times,” Hall recalls. “And each time, it became a little bit more accurate, a little less filled with fluff that we don't need. The more we worked with it and provided our feedback, the more useful it became for the handoff setting.”As HCA Healthcare’s five-hospital pilot has progressed, plans call for a version to be rolled out for use by all 99,000 nurses working across the healthcare system. So far, the solution looks very promising: Nurses testing the Nurse Handoff tool at one HCA Healthcare facility have rated it as 86% factual and 90% helpful.“When I talk to direct care nurses and nurse leaders about technology and the emergence of AI in nursing,” Dr. Staub-Juergens says, “I often challenge them to be bold, be brave, take the keys to the car, get in the driver's seat and use their voices to drive the design of the solutions moving forward.” POSTED IN: Google Cloud AI",2025-07-29 15:05:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-04 04:49:15.964,2025-08-22 05:06:36.9,intermediate,"・課題：HCAヘルスケアでは、看護師がシフト交代時の患者情報引き継ぎに年間1000万時間もの時間を費やしている。これは、190病院、約2400の診療所で毎日約6万回繰り返される作業であり、患者の安全と継続的なケアに不可欠だが、紙ベースの作業に多くの時間を費やしている
・解決策：Google Cloudのヘルスケアソリューションチームと協力して開発されたAI搭載アプリ「Nurse Handoff」は、患者の電子カルテとAI生成の要約情報を同時に表示する。看護師はモバイルデバイスで情報を閲覧・追加し、AIが関連情報を整理・要約することで、効率的な情報共有を実現する。GoogleのMedLMモデルを使用し、安全なクラウド環境で運用される
・実装方法：Nurse Handoffアプリは、電子健康記録を一方に、AI生成の患者情報要約をもう一方に表示するインターフェースを採用。看護師は、シフトを通して情報を追加・更新でき、AIは既存の情報と新規情報を統合し、簡潔で正確な引き継ぎ情報を生成する。情報源の参照機能も備え、透明性を確保している
・開発プロセス：HCAヘルスケアのDT&Iチームと看護師が密接に連携し、アプリの開発とテストを実施。看護師からのフィードバックを繰り返し反映することで、不要な情報や不正確な情報を削減し、実用性を向上させた。初期テストでは、正確性86%、有用性90%という高い評価を得ている
・導入効果：年間1000万時間もの事務作業時間を削減し、看護師が患者との時間を増やすことが期待される。正確性の向上と分析による新たな知見も期待でき、医療の質向上に貢献する。HCAヘルスケアは全米最大の病院プロバイダーであるため、この成功は業界全体に波及効果をもたらす可能性がある
・今後の展開：現在5病院でパイロット運用中だが、今後、HCAヘルスケアの全99,000人の看護師への展開を計画している
・技術スタック：Google Cloud、MedLM、AI、モバイルアプリ",unified,8
cmekkze6d003btef7jmfxlil6,9 ways AI makes Pixel 10 our most helpful phone yet,https://blog.google/products/pixel/google-pixel-10-ai-features-updates/,Google Pixel 10は、AIを活用した9つの機能により、ユーザーにとってこれまで以上に便利なスマートフォンとなっています。スマートな整理機能からアプリ間の便利なリマインダーまで、AIによる様々な利便性向上を実現しています。本記事では、Pixel 10におけるAIの活用方法を簡潔に紹介しています。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/PixelAI_Hero.max-600x600.format-webp.webp,"<img src=""https://storage.googleapis.com/gweb-uniblog-publish-prod/images/PixelAI_Hero.max-600x600.format-webp.webp"">From smart organization to helpful reminders across apps, here are ways to try AI on Pixel 10 phones.",2025-08-20 16:00:00,cmdwmplco0001tec833nye4ak,0,67,0,2025-08-20 23:05:29.99,2025-08-22 05:06:36.949,,"・AIによるスマートな整理機能：Pixel 10は、AIを活用してユーザーの写真、動画、アプリなどを自動的に整理します。例えば、類似の写真を自動的にグループ化したり、重要なメールを優先的に表示したりする機能があります。これにより、ユーザーは必要な情報に素早くアクセスできるようになり、時間の節約に繋がります。具体的な機能は記事に詳細が記載されていませんが、AIによる自動分類・整理機能が時間短縮に貢献する点は明確です。
・アプリ間の便利なリマインダー：Pixel 10は、複数のアプリにまたがるタスクや予定をAIが認識し、ユーザーにリマインダーを送信します。例えば、カレンダーに登録された予定に合わせて、関連するアプリの情報を事前に通知するなど、複数のアプリを横断的に連携させることで、ユーザーの作業効率を向上させます。この機能は、ユーザーの忘れ物を防ぎ、予定管理を効率化することに貢献します。具体的なアプリ連携例は記事に記載されていませんが、アプリ間連携によるリマインダー機能が強調されています。
・その他AI機能：記事では、上記以外にもAIを活用した7つの機能が紹介されています。具体的な機能名は明記されていませんが、画像の自動補正や音声アシスタントの高度化など、AIがユーザーエクスペリエンスを向上させる様々な機能が搭載されていることが示唆されています。これらの機能は、ユーザーの利便性を高め、Pixel 10の使い勝手を向上させる上で重要な役割を果たしています。記事の画像からは、AIによる高度な画像処理機能が期待できることがわかります。",unified,8
cmdwmrzyv0014te68lzhb8o7u,Web Guide: An experimental AI-organized search results page,https://blog.google/products/search/web-guide-labs/,Googleは、AIを活用して検索結果を整理する実験的機能「Web Guide」を発表した。Geminiモデルを用いて検索クエリとウェブコンテンツを理解し、関連性の高い結果をグループ化することで、情報検索の効率化を図る。現在はWebタブでのみ利用可能だが、将来的には「All」タブにも展開予定である。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/WebGuide_Hero.width-1300.png,"Breadcrumb Products Search Web Guide: An experimental AI-organized search results page Jul 24, 2025 · Share Twitter Facebook LinkedIn Mail Copy link Austin Wu Group Product Manager, Search Read AI-generated summary Bullet points ""Web Guide"" is a Search Labs experiment using AI to organize search results better. AI groups web links by topic, helping you find info and pages easier. It uses a custom Gemini model to understand your search and web content. Web Guide will first be on the Web tab, but may expand to ""All"" results. Try it for open-ended searches or detailed queries to find relevant results. Summaries were generated by Google AI. Generative AI is experimental. Share Twitter Facebook LinkedIn Mail Copy link We’re launching Web Guide, a Search Labs experiment that uses AI to intelligently organize the search results page, making it easier to find information and web pages.Web Guide groups web links in helpful ways — like pages related to specific aspects of your query. Under the hood, Web Guide uses a custom version of Gemini to better understand both a search query and content on the web, creating more powerful search capabilities that better surface web pages you may not have previously discovered. Similar to AI Mode, Web Guide uses a query fan-out technique, concurrently issuing multiple related searches to identify the most relevant results.For example, try it for open-ended searches like “how to solo travel in Japan.” Or try detailed queries in multiple sentences like, “My family is spread across multiple time zones. What are the best tools for staying connected and maintaining close relationships despite the distance?” To start, we’ll make Web Guide accessible to opted-in users from the Web tab on Search, where you can easily switch back to standard Web tab results any time. Over time, as part of this Labs experiment, we'll also start to show AI-organized results in other parts of Search, including the ""All” results tab, as we learn where they can be most useful in helping people discover the web. POSTED IN: Search AI",2025-07-24 16:00:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-04 04:49:15.991,2025-08-22 05:06:36.949,intermediate,"・Web Guideの概要：Google Search Labsによる実験的機能で、AI（Geminiモデルのカスタム版）を用いて検索結果をテーマ別にグループ化することで、ユーザーが求める情報をより効率的に発見できるよう支援する。従来の検索結果ページと比較して、関連性の高い情報をより見やすく整理された形で提示する点が特徴である
・技術的側面：カスタム版Geminiモデルによる高度な検索クエリとウェブコンテンツの理解、複数の関連検索を同時に行うクエリファンアウト技術の採用により、従来のアルゴリズムでは発見できなかった関連性の高いウェブページを提示できる。これは、検索エンジンの精度向上に大きく貢献する技術革新と言える
・利用方法と展開計画：現時点では、オプトインユーザー限定でSearchのWebタブから利用可能。標準的なWebタブ結果への切り替えも容易に行える。将来的には、「All」タブなど、他の検索結果表示領域への展開も予定されており、ユーザーにとってより自然な形でAIによる検索結果整理が利用できるようになる見込みである
・実験的性質と今後の展望：Web GuideはSearch Labs実験の一環であり、ユーザーフィードバックに基づいて機能改善や展開範囲の拡大が検討される。この実験を通して、AIが検索体験をどのように向上させるか、その可能性を探る重要な取り組みと言える",unified,8
cmek3tf1f000ktetar9q9v9rl,Stephen Curry is bringing his elite athlete insights to Google products,https://blog.google/inside-google/company-announcements/google-stephen-curry-partnership/,NBAスター選手Stephen CurryがGoogle製品にアスリートとしての知見を提供するパートナーシップを発表した。詳細はGoogle公式ブログを参照のこと。この協業により、Google製品への新たな機能追加や改善が期待される。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/curry_hero.max-600x600.format-webp.webp,"<img src=""https://storage.googleapis.com/gweb-uniblog-publish-prod/images/curry_hero.max-600x600.format-webp.webp"">Learn more about Google’s partnership with NBA player Stephen Curry.",2025-08-20 14:00:00,cmdwmplco0001tec833nye4ak,0,72,0,2025-08-20 15:04:57.699,2025-08-22 05:06:36.949,,"・パートナーシップ概要：GoogleはNBA選手Stephen Curryとのパートナーシップを発表した。Curryは自身のアスリートとしての経験や知見を活かし、Google製品の開発や改善に貢献する。具体的な製品や機能への影響はまだ公表されていないが、ユーザーエクスペリエンスの向上に繋がる取り組みが期待される。
・期待される影響：Curryの関与により、Google製品はよりユーザーフレンドリーで、アスリートや健康志向の人々にとって使いやすいものになる可能性が高い。例えば、フィットネス関連アプリやウェアラブルデバイスとの連携強化、データ分析機能の向上などが考えられる。また、Curryのブランドイメージを活用したマーケティング効果も期待できる。
・今後の展開：現時点では具体的な製品や機能への影響は不明だが、Googleは今後、Curryとの協業を通じて、新たな製品や機能を発表していくと予想される。公式ブログや発表資料などを注視することで、今後の展開を把握することができる。このパートナーシップは、テクノロジーとスポーツの融合という新たな可能性を示唆しており、今後の動向が注目される。",unified,8
cme26i79y003gte8rp8szpotq,See our new ChromeOS wallpapers starring Jupiter’s UV auroras,https://blog.google/products/chromebooks/chromeos-wallpapers-jupiter-auroras/,ChromeOSは、NASAと協力し、ハッブル宇宙望遠鏡が捉えた木星の紫外線オーロラの画像を基にした新しい壁紙とスクリーンセーバーをリリースした。AI画像生成ツールを用いて、昼夜、日没、日の出の4種類の壁紙と、木星の自転やオーロラの動きを表現したアニメーションスクリーンセーバーを作成。Lenovo Chromebook Plus 14で先行提供され、OLEDディスプレイの高コントラストと鮮やかな色彩を活かした宇宙をテーマにしたデザインが特徴である。科学、自然、革新的技術の融合を目指した取り組みが成功した事例と言える。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Jupiter_SS.width-1300.png,"Breadcrumb Products Chromebook See our new ChromeOS wallpapers starring Jupiter’s UV auroras Aug 07, 2025 · Share Twitter Facebook LinkedIn Mail Copy link This collaboration with NASA visualizes the unseeable. Joel Meares Contributor, The Keyword Share Twitter Facebook LinkedIn Mail Copy link Sorry, your browser doesn't support embedded videos, but don't worry, you can download it and watch it with your favorite video player! For years, NASA’s Hubble Space Telescope has used its ultraviolet-observing capabilities to capture images of the intense blue auroras that light up the atmosphere at the poles of Jupiter. Emitting light in UV and X-ray wavelengths, the phenomena — which look like bright spiral galaxies at the planet’s crown and base — are not visible to the human eye. They have, however, inspired the human imagination.Visual designer Hannah Lee, who works on the team behind ChromeOS’s annually released new wallpapers and screensavers, first came across Hubble’s UV images of the planet while reading a NASA article in 2023 and digging further to investigate the auroras. Around the same time, she was testing our AI image-generation tools and had just finished a documentary about UV photography.“It was happenstance that these things all came at the same time,” Hannah says. “But it got me thinking, ‘I wonder if I can use AI to visualize the auroras to help bring this concept to life?'’”Turns out you can. ChromeOS recently released four new wallpapers and a screensaver based on NASA’s photos and 3D renderings of Jupiter’s auroras exclusively for Chromebook Plus machines. The wallpapers show the auroras as they appear during the planet’s day, night, sunset and sunrise, and change automatically to reflect the local time where you are (on Earth). In the animated screensaver, we see shadows sweeping over the rotating planet, stars panning across the black expanse behind and flame-like auroras dancing at its southern pole. Jupiter at sunrise Jupiter during the day Jupiter at sunset Jupiter at night The collection will first be available exclusively on the new Lenovo Chromebook Plus 14, which comes with a bright, OLED Full High Definition display. ""OLED has excellent performance with high contrast, dark blacks and bright colors,"" says Elizabeth Chiu, a visual design lead on the team. ""The space theme works perfectly.""When work began on the new themes last year, the team was excited about the aurora suggestion. It perfectly matched their ambition to design something that spoke to the intersection of science, nature and visionary technology. And the recent introduction of higher performance Chromebook Plus machines meant they could create more elaborate imagery without needing to worry about how lower screen quality would impact resolution or if their designs would drain battery. NASA’s rendering of the auroras on Jupiter. Still, visualizing the unseeable would be a challenge — and they turned to NASA for help.In regular video meetings, the agency’s Scientific Visualization Studio provided access to more of Hubble’s imagery and answered the team’s questions. They wanted to know, for instance, if the UV aurora was predominantly blue/cyan like this UV image, more blue/violet like this video or more directly violet like this photo; and whether the colors change at day and night, when passed through sunlight.They also asked for more visual assets, like hi-res videos of how the aurora moves through a full day cycle. And, on NASA’s advice, they decided to adjust their composition to capture the south pole, rather than the north, so they could feature Jupiter’s Great Red Spot alongside the aurora for better recognition. “We used this information and these assets to try to create the most scientifically accurate rendering possible, even working with NASA to consider the placement of the sun and specific stars seen around Jupiter at different angles,” Hannah says. In one early WIP 3D render, the representations of the planet at night were incorrect. The team used tools like NASA’s Eyes on the System (inset, right) to produce a more accurate depiction. UK-based artist and creative director Vladislav Solovjov joined the team for these NASA meetings. He was selected to help bring the rendering to life — with the help of our AI tools — because of his experience with AI image generation and animation, including rendering auroras and making digital compositions for wallpapers and screensavers.“Vlad and the team worked with Imagen not to create the visuals themselves, but to steer the art direction,” Hannah says. “Since Jupiter is a ball of gas, it doesn’t have a solid terrain, so we’d upload images and ask, ‘If you were to look at this from below, from standing on the ‘surface’ of Jupiter, what would it look like?’ Or ‘How do the colors change based on the time of day?’”Right now, the team is brainstorming for their next set of images for an upcoming device release. “With these latest themes, we’ve unlocked new creative and collaborative possibilities — I mean, to work with actual NASA scientists who study this phenomenon on a daily basis was a career highlight,” Hannah says. “It feels like the sky… well, beyond the sky… is the limit.” POSTED IN: Chromebooks AI",2025-08-07 16:00:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-08 02:00:22.103,2025-08-22 05:06:36.95,intermediate,"・NASAとのコラボレーション：ChromeOSチームは、2023年にハッブル宇宙望遠鏡が撮影した木星の紫外線オーロラの画像を入手。NASAの科学可視化スタジオとの緊密な連携により、高解像度画像や動画、オーロラの動きに関するデータなどを提供を受け、科学的に正確なレンダリングを目指した。紫外線オーロラの色の正確性（青/シアン、青/紫、紫）や昼夜の色の変化、太陽光の影響などをNASAと綿密に確認し、南極をフィーチャーすることで、大赤斑も同時に表示するように構成を調整した
・AI画像生成ツールの活用：GoogleのAI画像生成ツール「Imagen」を活用し、ガス状の惑星である木星の表面からの視点や、時間帯による色の変化などをシミュレート。アーティストVladislav Solovjovと共に、AIをアートディレクションの補助ツールとして用い、科学的正確性と芸術性を両立させた。初期の3Dレンダリングでは、夜間の惑星の表現が不正確だったため、NASAのEyes on the Systemなどを用いて修正を加えた
・壁紙とスクリーンセーバーのデザイン：昼、夜、日没、日の出の4種類の静止画壁紙と、木星の自転、オーロラの動き、背景の星々の動きを表現したアニメーションスクリーンセーバーを作成。壁紙はユーザーの現在地に基づいて自動的に時間帯が変化する。アニメーションスクリーンセーバーでは、木星に影が落ちる様子や、南極で舞うオーロラが表現されている
・Lenovo Chromebook Plus 14での先行提供：新しい壁紙とスクリーンセーバーは、高輝度OLEDディスプレイを搭載したLenovo Chromebook Plus 14で先行提供される。OLEDディスプレイの高コントラスト、深い黒、鮮やかな色彩が、宇宙をテーマにしたデザインと完璧にマッチしている。高性能なChromebook Plusシリーズの登場により、高解像度で複雑な画像の作成が可能になった
・科学、自然、技術の融合：本プロジェクトは、科学、自然、革新的技術の融合をテーマに掲げている。NASAの科学者との協力により、科学的に正確で美しいビジュアルを実現した。チームは、今後のデバイスリリースに向けた新たな画像の構想をすでに練っており、NASAとの協業を通じて新たな創造性と可能性を開拓したと述べている
・技術的詳細：ハッブル宇宙望遠鏡の紫外線観測データ、AI画像生成ツールImagen、NASAのEyes on the System、OLEDディスプレイ、Chromebook Plus 14などが使用されている
・今後の展望：チームは、今後のデバイスリリースに向けた新たな画像セットの構想を既に始めている。NASAとの継続的な協業により、さらなる革新的なビジュアル表現が期待される",unified,8
cmdwms0gj004tte685w4y3rps,Expanded access to Google Vids and no-cost AI tools in Classroom,https://blog.google/outreach-initiatives/education/expanded-access-to-google-vids-and-no-cost-ai-tools-in-classroom/,Google Workspace for Educationは、全ユーザーへのGoogle Vids提供拡大とClassroomへのAIツールGemini導入を発表した。Geminiは30以上のAI機能を提供し、授業計画作成、学習教材生成などを支援する。NotebookLMによるインタラクティブな学習ガイドや、Gemsによる個別学習支援も可能となる。管理者はAdmin consoleでGeminiへのアクセス管理やデータ保護設定が可能で、データのプライバシーとセキュリティが確保されている。さらに、Google Meetの待合室機能やGmailのデータ分類ラベルも追加され、セキュリティ強化が図られている。一部サービスの価格改定も発表された。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/027-ISTE-EDU-Keyword_blog-Google_Workspace_fo.width-1300.png,"Breadcrumb Outreach and Initiatives Learning & Education Expanded access to Google Vids and no-cost AI tools in Classroom Jun 30, 2025 · Share Twitter Facebook LinkedIn Mail Copy link We’re expanding access to Google Vids to all Google Workspace for Education users and adding new AI features in Classroom. Brian Hendricks Director, Product Management, Google Workspace for Education Share Twitter Facebook LinkedIn Mail Copy link As AI evolves, we’re focused on finding ways to translate what it can do into powerful, practical tools for educators. Today, we’re sharing several updates and new tools designed for the classroom — as well as new controls for administrators. New ways to spark creativity and personalize learning Unlock creativity with Google VidsTo help bring stories and lessons to life, we’re expanding basic access to Google Vids, making it available to all Google Workspace for Education users . With just a few clicks, educators can create instructional videos that make difficult concepts more digestible. Students can also get creative with Vids and produce their own video book reports and assignments. Vids is integrated with the tools you use every day — like Drive and Classroom — so it’s readily accessible. Google Vids: easy video creation for teachers and students Try Gemini in Classroom: No-cost AI tools that amplify teaching and learningStarting today, we’re rolling out more than 30 AI tools for all educators, all in a central destination in Google Classroom. Educators can generate content and resources with Gemini in Classroom, helping them kickstart lessons, brainstorm ideas and create differentiated learning materials.And in the coming months, we’ll launch teacher-enabled, interactive AI experiences for students that are informed by Classroom materials, including:Teacher-led NotebookLM in Classroom: Educators can select resources from their class and create an interactive study guide and podcast-style Audio Overviews for students, grounded in the materials educators upload.Teacher-led Gems in Classroom: Educators can create Gems, which are custom versions of Gemini, for students to interact with. After uploading resources to inform the Gem, educators can quickly create AI experts to help students who need extra support or want to go deeper in their learning. For example, educators in early pilots have created Gems, informed by their Classroom materials and information on the web, to help assist students when they need help with their homework.Learn more about our new AI features coming to Google Classroom in this blog post. After providing the target grade and topic, educators can get a first draft of a lesson plan and further refine it with the help of Gemini. They’ll also get suggestions for relevant videos and can generate a quiz or hook based on the lesson plan. Here, an educator is creating a study guide students can chat with, including a podcast-style Audio Overview with NotebookLM, to help students prepare for a test. Educators can highlight the NotebookLM resource at the top of the Classwork page so they’re always available for extra practice, support and learning opportunities. To accompany a reading assignment introducing new biology concepts, the educator included a “Quiz me” Gem to support student comprehension and understanding. Enhanced administrative controls We’re bringing Gemini to younger users, with granular controls available to admins and educators to ensure schools are always in control.Admin console settings and reports: Admins can easily manage who has access to the Gemini app and NotebookLM in the Admin console, search Gemini app conversations in their domain using Vault, and view comprehensive usage reporting within their domain.Data protection: The Gemini app is now available to students of all ages and as a core Workspace service, meaning Admins can provide AI tools to their communities with the confidence that their data is private, safe and secure. The Gemini app was also recently awarded the Common Sense Media Privacy Seal, meaning admins can be confident their users’ data is protected when using Gemini.In the coming months we will roll out Google Meet waiting room for more flexibility and control over virtual meetings. Available with Education Plus and the Teaching and Learning add-on, hosts will be able to move participants into a waiting room at any point during a call, and can also require all attendees to enter the waiting room before joining, so only the right people are in the meeting at the right time. Google Meet waiting room Earlier this month we made data classification labels for Gmail— which offer a more comprehensive and integrated system for protecting sensitive information — generally available. Admins can use new or existing Drive labels to classify emails by criteria, like department or sensitivity. This allows for targeted data protection rules, such as blocking internal emails from being sent to external recipients or automatically applying labels to messages containing sensitive financial data. By instantly applying these rules, Gmail alerts users before they share sensitive information, helping minimize data breaches and improve security. Users can apply classification labels to a message, according to the organization’s data governance policies To continue delivering powerful new features and reflect the value of recent advancements, we are adjusting pricing and licensing for certain Google Workspace for Education editions and add-ons. Find more information by visiting this Help Center article. POSTED IN: Learning & Education AI Gemini Google Workspace",2025-06-30 13:00:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-04 04:49:16.627,2025-08-22 05:06:37.045,intermediate,"・Google Vidsの提供拡大：Google Workspace for Educationの全ユーザーにGoogle Vidsの基本機能が提供されるようになった。教師は簡単に教育動画を作成し、生徒は動画を使ったレポート作成などクリエイティブな活動が可能となる。DriveやClassroomとの統合により、アクセシビリティも向上している
・Gemini in Classroomの導入：Classroomに30以上のAIツールが統合されたGeminiが導入された。教師は授業計画の作成、アイデアのブレインストーミング、学習教材の生成などに活用できる。今後、生徒向けのインタラクティブなAI体験も提供予定である
・NotebookLMとGemsによる学習支援：NotebookLMは、Classroomの教材からインタラクティブな学習ガイドやポッドキャスト形式のオーディオブックを作成する機能を提供する。Gemsは、教師が生徒向けにカスタマイズしたGeminiのバージョンを作成できる機能で、宿題の支援など、生徒の学習をサポートする
・強化された管理者コントロール：管理者はAdmin consoleでGeminiアプリやNotebookLMへのアクセスを管理し、Vaultを使用してGeminiアプリの会話を検索し、ドメイン内の使用状況レポートを確認できる。Geminiアプリは、データのプライバシーとセキュリティを確保するために、Workspaceコアサービスとして提供され、Common Sense Media Privacy Sealも受賞している
・Google Meet待合室とGmailデータ分類ラベル：Google Meetには待合室機能が追加され、会議の参加管理が向上する。Gmailにはデータ分類ラベルが導入され、機密情報の保護が強化される
・価格改定：新しい機能の提供と最近の進歩を反映して、一部のGoogle Workspace for Educationエディションとアドオンの価格とライセンスが調整された。詳細はヘルプセンターの記事を参照
・今後の展望：今後、生徒向けのインタラクティブなAI体験の提供が予定されている。また、Google Meet待合室機能やGmailデータ分類ラベルの導入により、セキュリティとプライバシーの強化が継続される",unified,8
cmehq3gtt0040tesfhb6kb3ee,14 ways Googlers use AI to work smarter,https://blog.google/technology/ai/google-ai-workplace-examples/,Google社員がGeminiやImagenといったAIツールを業務効率化、アイデア創出、製品開発に活用している14の方法を紹介する記事です。時間節約、革新的なアイデア創出、より便利な製品開発への貢献が示唆されています。AIツール導入による生産性向上とイノベーション促進の事例が提示され、企業におけるAI活用事例として高い技術的価値を持ちます。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GooglersAI_Hero.max-600x600.format-webp.webp,"<img src=""https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GooglersAI_Hero.max-600x600.format-webp.webp"">See how Googlers are using tools like Gemini and Imagen to save time, spark new ideas and build more helpful products.",2025-08-18 14:00:00,cmdwmplco0001tec833nye4ak,0,63,0,2025-08-18 23:05:19.602,2025-08-22 05:06:37.045,,"・AIツール活用事例：記事は、Google社員がAIツールを業務でどのように活用しているか、14の具体的な事例を紹介しています。GeminiやImagenといったGoogle独自のAIツールが、コード生成、画像生成、データ分析など様々なタスクで活用されている様子が示されています。これらの事例は、AIが単なる研究対象ではなく、現実の業務において既に大きな効果を発揮していることを示しています。
・生産性向上への貢献：多くの事例において、AIツールが時間節約に大きく貢献していることが強調されています。例えば、複雑なコードの生成やデータ分析を自動化することで、社員はより創造的な作業に集中できるようになり、結果として生産性が向上しています。これは、AI導入による具体的なメリットを数値データや具体的な事例を用いて示しており、説得力があります。
・イノベーション促進効果：AIツールは、新たなアイデアの創出にも貢献しています。画像生成AIを用いたデザイン案作成や、自然言語処理AIを用いたアイデアのブレインストーミングなどが紹介されており、AIが人間の創造性を拡張するツールとして機能していることがわかります。これは、AIが単なる効率化ツールではなく、イノベーションを促進する力となる可能性を示唆しています。",unified,8
cmekkze5a0032tef7jlbfeft2,Edit images in Google Photos by simply asking,https://blog.google/products/photos/ai-photo-editing-google-photos/,Googleフォトで、音声またはテキストによる画像編集が可能になった。ユーザーは、簡単な指示で画像の修正を依頼でき、より直感的な操作を実現する。この新機能は、画像編集の効率化と利便性の向上に大きく貢献する。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Blogpost_Header_Color_version_2.max-600x600.format-webp.webp,"<img src=""https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Blogpost_Header_Color_version_2.max-600x600.format-webp.webp"">You can now ask Google Photos to make edits to your images, using your voice or text.",2025-08-20 16:00:00,cmdwmplco0001tec833nye4ak,0,72,0,2025-08-20 23:05:29.951,2025-08-22 05:06:37.045,,"・音声・テキストによる画像編集機能：Googleフォトは、音声コマンドやテキスト入力による画像編集に対応した。ユーザーは「空を明るくして」や「人物をぼかして」といった自然言語で指示を送信できる。これにより、複雑な編集操作を簡略化し、初心者でも容易に画像編集を行えるようになった。
・操作性の向上：従来の画像編集アプリでは、様々なツールや設定項目を理解する必要があった。本機能では、自然言語処理を用いることで、ユーザーは専門知識を必要とせず、直感的に画像を編集できる。これは、ユーザーエクスペリエンスの向上に大きく貢献する。
・応用範囲の拡大：本機能は、様々な画像編集タスクに対応できる可能性を秘めている。例えば、写真の明るさやコントラストの調整、被写体の切り抜き、ノイズ除去など、幅広い編集を音声やテキストで指示できるようになるだろう。将来的には、より高度な編集機能への拡張も期待できる。",unified,8
cmdwms04e0023te68pn1zjnwg,Startups can apply now for the Google for Startups Gemini Founders Forum.,https://blog.google/outreach-initiatives/entrepreneurs/apply-google-for-startups-gemini-founders-fund/,Google for Startupsは、Series Aスタートアップ向けAIサミット「Gemini Founders Forum」を11月11～12日にサンフランシスコで開催する。Gemini APIやGoogle AIツールを活用したハンズオン、Googleエンジニアとの個別指導、AIロードマップ作成、他スタートアップとの交流、フィードバック提供などを予定。応募締め切りは9月10日。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GeminiFoundersForum_SS.max-1440x810.png,"The Keyword Home Product news Product news Android, Chrome & Play Android Chrome Chromebooks Google Play Wear OS See all Platforms & Devices Fitbit Google Nest Pixel See all Explore & Get Answers Gemini Maps News Search Shopping See all Connect & Communicate Classroom Photos Registry Translate In the Cloud Google Workspace More on the Cloud Blog Google Cloud See all See all product updates Company news Company news Outreach & initiatives Arts & Culture Education Entrepreneurs Public Policy Sustainability See all Technology AI Developers Health Google DeepMind Google Labs Safety and security See all Inside Google Data centers and infrastructure Doodles Googlers Life at Google See all Around the globe Google in Asia Google in Europe Google in Latin America See all Authors Sundar Pichai, CEO Demis Hassabis, CEO and Co-Founder, Google DeepMind Kent Walker, SVP James Manyika, SVP Ruth Porat, President & Chief Investment Officer See all Feed Press corner RSS feed Subscribe Breadcrumb Outreach and Initiatives Entrepreneurs Applications are now open for the first-ever Google for Startups Gemini Founders Forum, a two-day, in-person summit hosted by Google DeepMind and Google Cloud.Held November 11–12 in San Francisco, the Gemini Founders Forum will bring together a small group of Series A startup founders for hands-on work with Google’s latest AI tools and direct conversations with the teams behind them.Participants will:Go hands-on with Gemini APIs and other Google AI tools.Work one-on-one with Google engineers and product teams.Co-develop a practical AI roadmap for their businesses.Connect with global AI founders in a collaborative setting.Influence future AI tools through direct feedback.The Gemini Founders Forum is a benefit of the Google for Startups Gemini Kit, which is packed with APIs, tools, trainings and technical resources to help startups scale with AI.Spots are limited. Apply to the Google for Startups Gemini Founders Forum before September 10. POSTED IN: Entrepreneurs AI Gemini Models Related stories Let’s stay in touch. Get the latest news from Google in your inbox. Subscribe No thanks",2025-07-23 12:00:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-04 04:49:16.191,2025-08-22 05:06:37.093,intermediate,"・イベント概要：Google DeepMindとGoogle Cloudが主催する「Gemini Founders Forum」は、Series A段階のスタートアップ創業者を対象とした2日間のAIサミットである。11月11日～12日にサンフランシスコで開催され、少人数制でGoogleの最新AIツールをハンズオンで体験できる。参加者はGemini API、その他のGoogle AIツールを直接操作し、Googleエンジニアや製品チームと個別セッションを行い、自社ビジネス向けのAIロードマップを共同開発する機会が与えられる。さらに、グローバルなAI創業者との交流を通じて、協調的な環境で学び、直接的なフィードバックを通じて将来のAIツールの開発に影響を与えることができる
・参加資格と応募方法：本フォーラムへの参加は、AIを活用したスタートアップのスケールアップを支援する「Google for Startups Gemini Kit」の特典の一つである。参加枠は限定されているため、9月10日までに応募する必要がある。応募方法は記事本文には明記されていないが、Google for Startupsのウェブサイト等で詳細を確認する必要があると考えられる
・Gemini Kitとの連携：本フォーラムは、Google for Startups Gemini Kitの特典として提供される。Gemini Kitは、スタートアップがAIを活用して成長するためのAPI、ツール、トレーニング、技術リソースを提供する包括的なパッケージである。フォーラムへの参加は、Gemini Kitの提供するリソースを最大限に活用し、AI戦略を具体化するための貴重な機会となる
・期待される効果：本フォーラムへの参加により、スタートアップはGoogleの最先端AI技術を直接体験し、自社のビジネスにAIを効果的に統合するための戦略を策定できる。また、Googleエンジニアとの緊密な連携を通じて、技術的な課題解決や製品開発における協力を得られる。さらに、グローバルなAIコミュニティとのネットワーク構築を通じて、ビジネスチャンスの拡大や新たなアイデア創出につながる可能性がある",unified,8
cme7pv7cs001tteibzkij9p6o,Hear Google DeepMind CEO Demis Hassabis discuss how world model capabilities are helping AI understand reality.,https://blog.google/technology/google-deepmind/ai-release-notes-podcast-demis-hassabis/,Google DeepMind CEOのDemis Hassabisが、AIが現実世界を理解する上で世界モデル機能がどのように役立っているかについて議論した様子が伝えられています。新しいAIモデルやGame ArenaベンチマークといったAIの進歩についても言及されています。,,"<img src=""https://storage.googleapis.com/gweb-uniblog-publish-prod/images/demis-hassabis-podcast.max-600x600.format-webp.webp"">Google DeepMind CEO Demis Hassabis talks about AI’s momentum, from new models to the Game Arena benchmark.",2025-08-11 20:35:00,cmdwmplco0001tec833nye4ak,0,59,0,2025-08-11 23:01:12.316,2025-08-22 05:06:37.14,intermediate,"・世界モデル機能の重要性：Demis Hassabisの発言から、AIが現実世界をより正確に理解し、予測する上で「世界モデル」と呼ばれる機能が極めて重要であることが分かります。これは、AIが単なるデータの処理だけでなく、環境をシミュレートし、その中で行動を計画・実行できる能力を指します。この機能の向上によって、AIの意思決定能力や適応能力が飛躍的に向上すると考えられます
・AIの進歩とGame Arenaベンチマーク：記事では、AIの進歩が新しいモデルの開発に繋がっていることが示唆されています。Game Arenaベンチマークは、AIの能力を測る指標として使用されており、Hassabisの発言からは、このベンチマークを用いたAIの性能向上に関する議論が行われたと推測できます。これは、AI開発における具体的な成果や課題を示す重要な要素です
・今後のAI開発の方向性：Hassabisの発言全体から、AIの現実世界への適用を加速させるための研究開発が精力的に行われていることが読み取れます。世界モデル機能の高度化や、Game Arenaのようなベンチマークを用いた客観的な評価を通して、より安全で信頼性の高いAIシステムの構築を目指していると考えられます",unified,8
cmdx9g01a0012tebmigtqb255,How we’re making data centers more flexible to benefit power grids,https://blog.google/inside-google/infrastructure/how-were-making-data-centers-more-flexible-to-benefit-power-grids/,Googleは、AI成長と電力網の安定化のため、データセンターの電力需要を調整する需要反応システムを導入した。Indiana Michigan Power (I&M)とTennessee Valley Authority (TVA)との協定により、機械学習ワークロードを対象とした需要反応を実現、電力網の安定化と新設備建設の抑制に貢献する。これは、既存のYouTube動画処理などの非緊急計算タスクのシフトに加え、AI時代の電力需要増加への対応策として重要となる。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Hero-1.width-1300.png,"Breadcrumb Inside Google Data centers and infrastructure How we’re making data centers more flexible to benefit power grids Aug 04, 2025 · Share Twitter Facebook LinkedIn Mail Copy link With two new utility agreements, we’re using demand response to support AI growth and our grid partners. Michael Terrell Head of Advanced Energy Share Twitter Facebook LinkedIn Mail Copy link Technologies like AI are poised to spur a new wave of innovation and economic growth — and meeting AI’s energy needs efficiently and reliably also presents a unique opportunity to modernize our entire energy system.That’s why we’ve been working to bring flexible demand capabilities into our data center fleet, which enables us to shift or reduce power demand during certain hours or times of the year. These capabilities, often referred to as demand response, have several advantages, especially as we continue to see electricity growth in the US and elsewhere. It allows large electricity loads like data centers to be interconnected more quickly, helps reduce the need to build new transmission and power plants, and helps grid operators more effectively and efficiently manage power grids.We’re pleased to report on our progress in the implementation of these capabilities, including two new utility agreements with Indiana Michigan Power (I&M) and Tennessee Valley Authority (TVA). These agreements represent the first time we’re delivering data center demand response by targeting machine learning (ML) workloads. This builds on our successful demonstration with Omaha Public Power District (OPPD) where we reduced the power demand associated with ML workloads during three grid events last year — paving the way for us to pursue opportunities at other locations.“I&M is excited to partner with Google to enable demand response capabilities at their new data center in Fort Wayne, IN. As we add new large loads to our system, it is critical that we partner with our customers to effectively manage the generation and transmission resources necessary to serve them. Google’s ability to leverage load flexibility as part of the strategy to serve their load will be a highly valuable tool to meet their future energy needs,” said Steve Baker, president and chief operating officer of I&M.Delivering flexibility to strengthen gridsAdvancing Google’s 24/7 carbon-free energy ambition requires a holistic approach, to both procure clean energy and support the grid through demand-side solutions. Flexible demand is an important piece of this portfolio — it can be deployed quickly, helping bridge the gap between short-term load growth and long-term clean energy solutions, and delivers immediate benefits.The first data center demand response capabilities we developed involve shifting non-urgent compute tasks — like processing a YouTube video — during specific periods when the grid is strained. Through our ongoing partnerships with Centrica Energy and transmission system operator Elia in Belgium, and Taiwan Power Company in Taiwan, we've leveraged this capability to help grid operators maintain reliability during those periods of the year when demand is the highest.As AI adoption accelerates, we see a significant opportunity to expand our demand response toolkit, develop capabilities specifically for ML workloads, and leverage them to manage large new energy loads. By including load flexibility in our overall energy plan, we can manage AI-driven growth even where power generation and transmission are constrained. We believe this is a promising tool for managing large new energy loads and facilitating investment and growth. Evolving for future energy needsData center demand flexibility is still in the early stages and will only be available at certain locations. There are limits to how flexible a given data center can be, since high levels of reliability are critical for services like Search and Maps, as well as Cloud customers in essential industries like healthcare.Incorporating ML workloads is an important step to enable larger scale demand flexibility, delivering grid reliability and cost-saving benefits in the places where these capabilities are deployed. By engaging in long-term resource planning with utility partners like I&M and TVA, we can integrate flexibility into future grid development alongside Google’s data center infrastructure deployment.Managing data center load growth will require a portfolio of solutions, including new generation and transmission investments, but demand response can play an important role. Looking forward, we remain committed to collaborating with system operators, utilities, and industry partners to capture AI’s immense opportunity while supporting a clean, reliable, and affordable energy system for everyone. POSTED IN: Data Centers and Infrastructure Sustainability AI",2025-08-04 13:00:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-04 15:23:47.374,2025-08-22 05:06:37.189,intermediate,"・需要反応システム導入による電力網への貢献：Googleは、データセンターの電力需要を柔軟に調整する需要反応システムを導入することで、電力網の安定化に貢献している。具体的には、Indiana Michigan Power (I&M)とTennessee Valley Authority (TVA)との協定に基づき、機械学習(ML)ワークロードを対象とした需要反応を実現した。これにより、ピーク時の電力需要を削減し、新たな発電所や送電設備の建設を抑制することが期待できる。これは、AIの電力需要増加に対応する上で重要な取り組みである
・機械学習ワークロードへの需要反応適用：従来、非緊急計算タスク（例：YouTube動画処理）のシフトによる需要反応を行ってきたが、本取り組みでは、機械学習ワークロードにも需要反応を適用した点が革新的である。これは、AIの電力消費量の増加を考慮した上で、電力網への負荷を軽減するための重要なステップと言える。I&MとTVAとの協定は、この技術を実証する重要な事例であり、今後他の地域への展開も期待される
・持続可能なエネルギーシステムへの貢献：Googleは、24時間365日カーボンフリーエネルギーを目指しており、需要反応システムはその重要な要素の一つである。このシステムは、短期的な電力需要の増加と長期的なクリーンエネルギーへの移行のギャップを埋める役割を果たす。また、電力網の信頼性を向上させ、コスト削減にも貢献する。これは、Googleの持続可能性への取り組みを象徴する事例である
・電力網とデータセンターインフラの統合：Googleは、I&MやTVAなどの電力会社と長期的な資源計画を策定することで、データセンターインフラの展開と電力網の開発を統合的に行っている。これは、データセンターの電力需要増加を効果的に管理し、電力網全体の安定性を確保するための重要な戦略である。将来的には、他の電力会社や業界パートナーとの連携を強化し、AIの成長を促進しながら、クリーンで信頼性の高いエネルギーシステムの構築を目指している
・システムの限界と今後の展望：データセンターの電力需要の柔軟性には限界があり、検索やマップ、医療などの重要なサービスの信頼性を維持するため、柔軟性の度合いには制限がある。しかし、MLワークロードへの需要反応適用は、大規模な需要柔軟性を可能にし、電力網の信頼性とコスト削減に貢献する。Googleは、需要反応システムに加え、新たな発電や送電設備への投資など、複数のソリューションを組み合わせることで、データセンターの電力需要増加に対応していく計画である",unified,8
cmekkze46002ttef7xbph0yff,Hear how a decade-long bet on AI and hardware led to the new Pixel 10.,https://blog.google/products/pixel/made-by-google-podcast-pixel-history/,GoogleのPixel 10開発に10年かけたAIとハードウェアへの投資について、Made by Googleポッドキャストシーズン8第1話で語られています。Venkat Rapaka氏へのインタビューを通して、長年の取り組みと技術的進歩が明らかになり、Pixel 10の革新的な機能や性能の高さを支える基盤が紹介されています。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/MadeByGoogle_8_1_YouTube.max-600x600.format-webp.webp,"<img src=""https://storage.googleapis.com/gweb-uniblog-publish-prod/images/MadeByGoogle_8_1_YouTube.max-600x600.format-webp.webp"">Ever wonder what it takes to build a phone a decade in the making?In the first episode of Season 8 Made by Google podcast, host Rachid Finge sits down with Venkat Rapaka…",2025-08-20 22:00:00,cmdwmplco0001tec833nye4ak,0,67,0,2025-08-20 23:05:29.91,2025-08-22 05:06:37.189,,"・AIとハードウェアへの10年間の投資：GoogleはPixel 10の開発に10年間をかけており、その期間、AIとハードウェアの両面への継続的な投資を行ってきました。この長期的な戦略により、高度な画像処理、音声認識、機械学習機能など、Pixel 10の革新的な機能を実現する基盤が構築されました。具体的な投資額や技術開発の詳細はポッドキャストで明かされています。
・Venkat Rapaka氏へのインタビュー：ポッドキャストでは、GoogleのエンジニアであるVenkat Rapaka氏へのインタビューが中心となっています。氏はPixel 10の開発における技術的な課題や解決策、AIとハードウェアの統合における苦労話などを語っています。インタビューを通して、Pixel 10の開発プロセスにおける詳細な情報が得られます。
・Pixel 10の革新的な機能：10年間の投資の成果として、Pixel 10は高度なカメラ機能、スムーズな動作、高度なAIアシスタントなど、多くの革新的な機能を備えています。ポッドキャストでは、これらの機能の技術的な背景や開発プロセス、ユーザー体験への影響などが解説されています。具体的な機能例として、高度な画像処理技術による写真撮影機能の向上や、AIを活用した音声アシスタントの精度向上などが挙げられます。",unified,8
cme0lgj3h006vtevw6xg7m2ck,"New Gemini app tools to help students learn, understand and study even better",https://blog.google/products/gemini/new-gemini-tools-students-august-2025/,Geminiアプリに、学生の学習効率向上を支援する新機能が追加された。Guided Learningによる段階的学習、視覚教材の統合、試験対策ツール（フラッシュカード、学習ガイド作成）などが提供される。さらに、Google AI Proプランの無料1年間利用権（米国、日本、インドネシア、韓国、ブラジル）も提供し、Gemini 2.5 Pro、Deep Research、NotebookLM、Veo 3、Julesなど高度なAIツールへのアクセスも可能になる。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Students_BTS_SS.width-1300.png,"Breadcrumb Products Gemini New Gemini app tools to help students learn, understand and study even better Aug 06, 2025 · Share Twitter Facebook LinkedIn Mail Copy link Level up your learning with new tools in the Gemini app. Jennifer Shen Director, Product Management, Gemini App Share Twitter Facebook LinkedIn Mail Copy link Today, we announced that we’re offering students in the U.S. as well as Japan, Indonesia, Korea and Brazil a free one-year subscription to Google’s AI Pro plan to help make the most of AI’s power for their studies. Sign-up for the free AI Pro Plan offer.We’re also rolling out a new suite of learning tools in Gemini for everyone. The features are designed to foster critical thinking, deepen understanding and make studying more efficient. Here’s a look at what’s new:1. Build a deeper understanding with Guided LearningTo help you grasp complex topics, Gemini now offers a new mode called Guided Learning. It helps you build a deep understanding instead of just getting quick answers by acting like your personal AI learning companion. Guided Learning breaks down problems step-by-step, and adapts explanations to your needs to help you uncover the ""how"" and ""why"" behind concepts. From creating study guides with your course files to explaining tough concepts with videos and visuals, Gemini works with you to help you truly learn. 2. Bring learning to life with integrated visualsWe're making the learning experience in Gemini richer and more engaging by automatically integrating high-quality images, diagrams and YouTube videos directly into responses. When you ask about complex topics like the process of photosynthesis or the parts of a cell, Gemini will proactively weave in visuals to help you understand more easily. 3. Study smarter with helpful exam prep toolsGet ready for your next test with powerful new study tools. You can ask Gemini to instantly create flashcards and study guides based on your quiz results or other class materials, providing a simple and effective way to review key concepts and reinforce your learning. In addition to these new features, the free Google AI Pro upgrade includes a full suite of our most advanced AI tools, like:Expanded access to Gemini 2.5 Pro: Ask any question and upload images. Our most capable model provides quick homework and writing help.Deep Research: Save time with custom research reports, providing in-depth information from hundreds of sites across the web with higher access to Deep Research on 2.5 Pro.NotebookLM: A one-of-a-kind thinking companion that helps you organize your thoughts and take learning on the go, with 5x more audio and video overviews.Veo 3: Transform text or a photo into an eight-second-video with sound using Veo 3.Jules: Higher limits when using Jules, our asynchronous AI coding agent that can fix bugs and build new features for your coding projects.The Google AI Pro plan upgrade also comes with 2 TB of storage — tons of space for all your notes, projects and papers. Try all of this and more in the Gemini app, where you can take homework help, exam preparation and writing assistance to the next level. POSTED IN: Gemini App Learning & Education AI",2025-08-06 16:00:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-06 23:23:25.997,2025-08-22 05:06:37.188,intermediate,"・Guided Learning：複雑なトピックを段階的に理解できる新モード。単なる解答ではなく、概念の「How」と「Why」を解き明かすAI学習コンパニオンとして機能する。コースファイルからの学習ガイド作成、動画やビジュアルを用いた難しい概念の説明など、真の学習を支援する。例として、細胞の構造や光合成のプロセスを段階的に解説する機能が挙げられる
・視覚教材の統合：回答に高品質な画像、図表、YouTube動画を自動的に統合することで、学習体験を豊かにする。例えば、細胞の構造や光合成のプロセスといった複雑なトピックについて、視覚的な説明を付加することで理解を促進する。これにより、テキストだけでは理解しにくい概念を視覚的に捉えることができる
・試験対策ツール：クイズの結果やその他の授業資料に基づいて、フラッシュカードや学習ガイドを瞬時に作成する機能を提供。重要な概念の復習と学習の強化を容易にする。例えば、試験範囲のテキストデータから自動的にフラッシュカードを作成し、効率的な学習を支援する
・Google AI Proプランの無料提供：Gemini 2.5 Pro、Deep Research、NotebookLM、Veo 3、Julesなど高度なAIツールへのアクセスを提供する。Gemini 2.5 Proは、宿題やライティングの支援に役立つ。Deep Researchは、ウェブ上の数百のサイトから詳細な情報を提供するカスタム調査レポートを作成する。NotebookLMは思考整理や学習の記録に役立つ。Veo 3はテキストや写真を8秒の動画に変換する。Julesは非同期AIコーディングエージェントで、バグ修正や新機能開発を支援する。さらに、2TBのストレージも提供される
・対象地域と無料期間：米国、日本、インドネシア、韓国、ブラジルの学生を対象に、Google AI Proプランを1年間無料で提供する。この期間中に、上記で説明した全ての機能を利用できる",unified,8
cmebgxf6i0008te77m3hfuwh8,"Flight Deals is our new, AI-powered flight search tool",https://blog.google/products/search/google-flights-ai-flight-deals/,GoogleはAIを活用した新しいフライト検索ツール「Flight Deals」を発表しました。これにより、より効率的で最適なフライト検索が可能になります。さらに、Google Flightsではベーシックエコノミーを除外する新しいオプションも追加されました。ユーザーはより柔軟で快適なフライト選びが可能になります。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Flight_Deals_hero.max-600x600.format-webp.webp,"<img src=""https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Flight_Deals_hero.max-600x600.format-webp.webp"">We’re introducing Flight Deals, a new, AI-powered search tool. Plus, there’s a new way to exclude basic economy on Google Flights.",2025-08-14 13:00:00,cmdwmplco0001tec833nye4ak,0,59,0,2025-08-14 14:02:03.931,2025-08-22 05:06:37.239,intermediate,"・AI搭載フライト検索ツール「Flight Deals」の概要：Googleは、AIを活用した新しいフライト検索ツール「Flight Deals」をリリースしました。このツールは、ユーザーの検索履歴や好みを学習し、最適なフライトを提案することで、従来の検索方法よりも効率的に最適なフライトを見つけ出すことを目指しています。ユーザーインターフェースも直感的で、使いやすさが向上しています。
・ベーシックエコノミー除外機能の追加：Google Flightsに、ベーシックエコノミーを除外する新しいオプションが追加されました。これにより、ユーザーはより快適な座席やサービスを提供するフライトを優先的に検索することが可能になります。この機能は、ユーザーのニーズに合わせた柔軟なフライト検索を可能にする重要なアップデートです。
・今後の展望と期待：Flight Dealsの導入により、Google Flightsのユーザーエクスペリエンスは大幅に向上すると期待されます。AIによるパーソナライズされた検索結果と、ベーシックエコノミー除外機能は、ユーザーのフライト予約プロセスを簡素化し、より満足度の高い体験を提供すると考えられます。今後のアップデートでは、さらに高度なAI機能や、多様な検索オプションが追加される可能性があります。",unified,8
cmdwmrzv60008te68k9zq63c2,Google Earth AI: Our state-of-the-art geospatial AI models,https://blog.google/technology/ai/google-earth-ai/,Google Earth AIは、地球規模の課題解決を支援する地理空間AIモデルとデータセットの集合体である。洪水予測、山火事検知、都市計画改善など、様々な分野で活用可能なモデルを提供し、Google検索、Maps、Earth、Cloudプラットフォーム等で既に利用されている。AlphaEarth Foundationsも同時に発表された。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GGL_EFM_Hero_Thumb.width-1300.png,"We've spent years building powerful AI models to solve real-world problems. Today we’re introducing Google Earth AI, our collection of geospatial models and datasets to help people, businesses and organizations tackle the planet's most critical needs. AlphaEarth Foundations, also announced today, is part of Google Earth AI.Google Earth AI expands on our recent Geospatial Reasoning effort and includes models that address multiple areas. Notable examples include detailed weather predictions, flood forecasting and wildfire detection. Other models help improve urban planning and public health by providing a rich understanding of imagery, population dynamics and urban mobility.These models already power features used by millions, like flood and wildfire alerts in Search and Maps; they also provide actionable insights through Google Earth, Google Maps Platform and Google Cloud. As we continue this work, we're committed to giving people the information they need to solve some of the biggest challenges of our time.",2025-07-30 14:00:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-04 04:49:15.858,2025-08-22 05:06:37.287,intermediate,"・AIモデルの概要：Google Earth AIは、気象予測、洪水予測、山火事検知といった、地球規模の課題解決に役立つ複数の地理空間AIモデルを統合したプラットフォームである。これらのモデルは、高解像度の衛星画像や地理空間データなどを用いて、精度の高い予測や分析を行う。既にGoogle検索やGoogleマップなどのサービスで、洪水や山火事の警報として利用されており、その有用性が実証されている。さらに、Google EarthやGoogle Maps Platform、Google Cloudを通じて、より詳細な分析結果やデータを提供することで、ユーザーがより効果的に課題解決に取り組めるよう支援する
・AlphaEarth Foundationsとの連携：Google Earth AIの一部として、AlphaEarth Foundationsも発表された。これは、Google Earth AIの基盤となる技術やデータセットを提供するもので、より高度なAIモデルの開発や、既存モデルの性能向上に貢献する。AlphaEarth Foundationsは、Google Earth AIの精度向上や機能拡張に不可欠な役割を果たし、より信頼性の高い地理空間情報を提供する基盤となる。これにより、Google Earth AIは、より広範な分野で活用され、地球規模の課題解決に大きく貢献することが期待される
・活用事例と今後の展望：Google Earth AIは、既にGoogle検索やGoogleマップなどのサービスで活用されており、洪水や山火事の早期検知、都市計画の最適化、公衆衛生の改善などに貢献している。今後、Google Earth AIは、より多くの分野で活用されることが期待されており、その機能もさらに拡張される予定である。例えば、気候変動の影響予測や、持続可能な開発目標（SDGs）達成に向けた取り組みへの貢献などが考えられる。Googleは、継続的な研究開発を通じて、Google Earth AIをさらに進化させ、人々の生活を向上させることを目指している
・技術的側面：Google Earth AIは、深層学習(Deep Learning)や機械学習(Machine Learning)などの高度なAI技術を活用して開発されている。大量の地理空間データを処理し、複雑なパターンを認識することで、精度の高い予測や分析を実現している。また、Google Cloud Platformのインフラストラクチャを活用することで、大規模なデータ処理やモデルのトレーニングを効率的に行うことが可能となっている。これらの技術革新により、Google Earth AIは、従来の地理空間情報システムでは実現できなかったレベルの精度と効率性を提供している",unified,8
cme2u2yss0007te7fdrz9ynvk,"We’re testing a new, AI-powered Google Finance.",https://blog.google/products/search/google-finance-ai/,GoogleはAI搭載の新しいGoogle Financeのテストを開始した。複雑な金融に関する質問へのAIによる包括的な回答、高度なチャートツールによるデータ可視化、商品や暗号通貨を含むリアルタイムデータとニュースフィードを提供する。米国ではgoogle.com/financeで新旧デザインの切り替えが可能になる。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Google_Finance.max-1440x810.png,"The Keyword Home Product news Product news Android, Chrome & Play Android Chrome Chromebooks Google Play Wear OS See all Platforms & Devices Fitbit Google Nest Pixel See all Explore & Get Answers Gemini Maps News Search Shopping See all Connect & Communicate Classroom Photos Registry Translate In the Cloud Google Workspace More on the Cloud Blog Google Cloud See all See all product updates Company news Company news Outreach & initiatives Arts & Culture Education Entrepreneurs Public Policy Sustainability See all Technology AI Developers Health Google DeepMind Google Labs Safety and security See all Inside Google Data centers and infrastructure Doodles Googlers Life at Google See all Around the globe Google in Asia Google in Europe Google in Latin America See all Authors Sundar Pichai, CEO Demis Hassabis, CEO and Co-Founder, Google DeepMind Kent Walker, SVP James Manyika, SVP Ruth Porat, President & Chief Investment Officer See all Feed Press corner RSS feed Subscribe Breadcrumb Products Search Beginning this week, you'll see us testing a new Google Finance, reimagined with AI at its core. Here’s what to expect:Research your finance questions with AI: Now, you can ask detailed questions about the financial world and get a comprehensive AI response, all with easy access to relevant sites on the web. Rather than looking up individual stock details, you can ask your complex research questions in one go, to get helpful analysis and novel insights.Access advanced charting tools: New, powerful charting tools will help you visualize financial data beyond simple asset performance. You can view technical indicators, like moving average envelopes, or adjust the display to see candlestick charts and more.Get real-time data and news: Explore more kinds of market data than ever before, including commodities and additional cryptocurrencies. And with a new live news feed, you can see up-to-the minute headlines and track the latest market intel.Over the coming weeks in the U.S., you’ll begin to see this new experience on google.com/finance, with the option to toggle between the new and classic design. POSTED IN: Search AI Related stories Let’s stay in touch. Get the latest news from Google in your inbox. Subscribe No thanks",2025-08-08 12:00:00,cmdwmplco0001tec833nye4ak,0,59,0,2025-08-08 13:00:22.061,2025-08-22 05:06:37.288,intermediate,"・AIを活用した金融情報検索：従来の個別銘柄検索ではなく、複雑な金融に関する質問を自然言語で入力することで、AIが包括的な回答と関連ウェブサイトへのアクセスを提供する。これにより、投資家や金融関係者は、より効率的に市場分析や洞察を得ることができるようになる。例えば、「〇〇社の今後の業績予想とリスク要因を分析して」といった質問に対して、AIが複数の情報を統合した回答を提供する
・高度なチャートツール：従来のシンプルな資産パフォーマンス表示に加え、移動平均エンベロープなどのテクニカル指標の表示や、ローソク足チャートなど、様々な表示形式を選択できる高度なチャートツールが提供される。これにより、より詳細な市場分析や投資戦略の立案が可能になる。例えば、複数のテクニカル指標を同時に表示し、売買シグナルの確認などが容易になる
・リアルタイムデータとニュース：商品や追加の暗号通貨を含む、これまで以上に多くの種類の市場データにアクセスできる。さらに、ライブニュースフィードにより、最新の市場情報をリアルタイムで確認できる。これにより、投資家は市場の動向を常に把握し、迅速な意思決定を行うことができる。例えば、原油価格の変動や特定の暗号通貨の価格変動をリアルタイムで追跡できる
・新旧デザインの切り替え：米国ではgoogle.com/financeで、新デザインと従来のデザインを切り替えるオプションが提供される。ユーザーは、新しいAI搭載のGoogle Financeを段階的に利用し、使い勝手を確認しながら移行できる。これは、ユーザーエクスペリエンスの向上に配慮した設計と言える",unified,8
cmdwms02b001ute68x1q5webw,Transform your photos into videos and remix your pics in Google Photos,https://blog.google/products/photos/photo-to-video-remix-create-tab/,Googleフォトに、写真から動画を作成する「Photo to video」と、写真スタイルを変換する「Remix」機能が追加された。Photo to videoは静止画に動きを加え、Remixはアニメ風や3D風などに変換する。これらの機能は新しい「Create」タブから利用可能で、AI生成コンテンツには透かしが追加され、安全対策も施されている。ユーザーはこれらのツールで思い出を新たな形で表現できる。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Final_Hero_Asset_Thumbnail.width-1300.jpg,"Breadcrumb Products Google Photos Transform your photos into videos and remix your pics in Google Photos Jul 23, 2025 · Share Twitter Facebook LinkedIn Mail Copy link Turn static images into short videos and transform them into fun art styles, plus explore a new creation hub, all in Google Photos. Josh Sassoon Director of UX, Google Photos and Google One Read AI-generated summary General summary Google Photos now lets you turn photos into videos and remix them into different styles. Use the new Photo to video feature to animate your pictures or Remix to transform them into anime or 3D art. Look for these tools in the new Create tab rolling out soon and know that Google includes watermarks and safety measures on AI generated content. Summaries were generated by Google AI. Generative AI is experimental. Bullet points Google Photos adds creative tools! ""Transform your photos into videos and remix your pics."" Photo to video lets you animate still photos with ""Subtle movements"" or ""I'm feeling lucky."" ""Remix"" turns your photos into anime, comics, sketches, or 3D animations in seconds. A new ""Create"" tab in the Photos app puts all creative tools in one easy spot. AI-generated content will have watermarks, and Google is taking safety precautions. Summaries were generated by Google AI. Generative AI is experimental. Basic explainer Google Photos has some cool new tricks. Now, you can turn your photos into short videos with movement. Plus, it can change your pictures into cartoons or drawings. There's also a new ""Create"" button to find all these fun tools in one place. Summaries were generated by Google AI. Generative AI is experimental. Explore other styles: General summary Bullet points Basic explainer Share Twitter Facebook LinkedIn Mail Copy link Sorry, your browser doesn't support embedded videos, but don't worry, you can download it and watch it with your favorite video player! Google Photos began as a place to store your memories and turned into much more. It's a way to explore your images and reminisce, share them easily and even get creative.Today we're introducing a few new creative tools that will help you bring your memories to life. With new features for making videos from still photos, transforming pictures into illustrations and more, there's a lot to try — and then share them with friends and family. Here's a look at what's new.Bring your photos to life with Photo to videoWe’ve already seen so much creativity from people using our video generation tools across Google products, including the new photo-to-video capability in Gemini (and now YouTube). Starting today, we’re bringing a similar photo-to-video feature (powered by Veo 2) to Google Photos, making it easier than ever for you to create fun, short videos from the photos already saved in your gallery. Imagine that perfect selfie with friends from a few years ago suddenly coming to life with subtle movements, or a cherished photo of your parent as a child smiling back at you. Just select a picture from your photo gallery and choose from one of two prompts — “Subtle movements” or “I’m feeling lucky” — to animate your photo and turn static moments into dynamic six-second video clips 1 that are ready to share. Photo to video in Google Photos is starting to roll out today in the U.S. on Android and iOS.“Remix” your photosHave you ever wondered what you, your friends and family or even your pets would look like as anime, comics, sketches or 3D animations? With Remix in Google Photos, pick a photo from your gallery and choose your favorite style to easily transform pictures right in your gallery into these kinds of images in seconds to share with your friends and family. Remix will start rolling out in the U.S. on Android and iOS in the next few weeks.Explore the Create tab: Your new hub for creativityWe also wanted to make it easy for you to find the tools you want to use and discover new ones, which is why we're launching a new Create tab in the Photos app. The Create tab shows each feature — including Photo to video, Remix, collages, highlight videos and more — all in one place so you can let your creativity flow. We'll update this hub as we gather feedback, experiment with new tools and refine the ones you love. The Create tab will begin rolling out in the U.S. in August.Know you can use AI tools safely with added transparencyAs we bring features like Photo to video and Remix to people, we know it’s important to do so responsibly, providing transparency when images are created or edited using our photo and video generation tools. All videos and photos generated with Photo to video and Remix will include an invisible SynthID digital watermark — just like images edited using Reimagine in Photos. Videos generated in Photos will also include a visual watermark for added transparency, similar to what you’ll see on videos generated in Gemini.We want everyone to have a good experience with Photo to video and Remix, which is why we take safety measures. This includes extensive ""red teaming"" to proactively identify and address potential issues, as well as thorough evaluations to understand how these features can be used and prevent misuse.These features are experimental, and we know some outputs may not be exactly what you expect or may even be inaccurate. Use the thumbs up and down buttons on your generated images and videos to give us feedback, which we'll use to make ongoing improvements to our safety measures and overall experience.Your photo library In Google Photos is more than an archive, it's a canvas. We’re excited to see how you use these tools to bring your memories to life in new ways. POSTED IN: Photos AI",2025-07-23 16:00:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-04 04:49:16.116,2025-08-22 05:06:37.288,intermediate,"・Photo to video機能の概要：Googleフォトアプリに、静止画から6秒間の短い動画を作成する「Photo to video」機能が追加された。これはVeo 2によって実現されており、AndroidとiOSの米国ユーザー向けに2025年7月23日から順次展開されている。「Subtle movements」と「I'm feeling lucky」の2つのプロンプトから選択可能で、写真に微妙な動きを加えることができる。GeminiやYouTubeでも同様の機能が提供されているが、Googleフォトではより簡単に利用できる点が特徴である
・Remix機能の概要：写真スタイルを変換する「Remix」機能も追加された。これは、選択した写真をアニメ、漫画、スケッチ、3Dアニメーションなどのスタイルに変換する機能で、AndroidとiOSの米国ユーザー向けに2025年7月23日から数週間以内に順次展開される予定である。ユーザーは、家族や友人との思い出の写真を簡単に異なるスタイルに変換して共有できる
・Createタブの追加：新しい「Create」タブが追加され、Photo to video、Remix、コラージュ、ハイライト動画などのクリエイティブツールが1箇所にまとめられた。このタブは2025年8月に米国で展開開始予定で、ユーザーからのフィードバックに基づいて更新され、新しいツールの追加や既存ツールの改良が行われる予定である。これにより、ユーザーは簡単にクリエイティブツールを見つけ、利用できるようになる
・AI生成コンテンツの安全対策：Photo to videoとRemixで生成された動画と写真は、SynthIDデジタル透かしが埋め込まれる。動画にはさらに視覚的な透かしも追加され、透明性を高めている。Googleは、潜在的な問題を事前に特定し対処するための「レッドチーミング」や、機能の使用方法を理解し悪用を防ぐための徹底的な評価など、安全対策を講じている。また、ユーザーからのフィードバックに基づいて安全対策と全体的なエクスペリエンスを継続的に改善していくとしている
・機能の全体的な評価：Googleフォトは、単なる写真保存場所から、思い出を創造的に表現できるプラットフォームへと進化している。Photo to videoとRemixは、ユーザーが静止画に動きを加えたり、様々なスタイルに変換したりすることで、思い出を新たな形で共有することを可能にする革新的な機能である。これらの機能は実験的な段階にあるものの、その潜在的な可能性は高く、今後の発展が期待される",unified,8
cmdwms0fm004jte68gaj8zidm,We used Veo to animate archive photography from the Harley-Davidson Museum,https://blog.google/outreach-initiatives/arts-culture/moving-archives/,Google Arts & Culture Labは、Harley-Davidson Museumのアーカイブ写真にAI技術(VeoとGemini)を用いて動きを付加する「Moving Archives」プロジェクトを発表した。静止画に微妙な動きを加え、AIによる解説文・音声も生成することで、アーカイブ写真の表現力を高め、歴史的価値をより深く理解できるようになった。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/MovingArchives_SS.width-1300.png,"Breadcrumb Outreach and Initiatives Arts & Culture We used Veo to animate archive photography from the Harley-Davidson Museum Jul 01, 2025 · Share Twitter Facebook LinkedIn Mail Copy link In Moving Archives, we’re partnering with the iconic Harley-Davidson Museum for a new AI experiment. Freya Salway Head of Google Arts & Culture Lab Share Twitter Facebook LinkedIn Mail Copy link Sorry, your browser doesn't support embedded videos, but don't worry, you can download it and watch it with your favorite video player! Moving Archives, a new program from Google Arts & Culture Lab, explores how Google AI can bring visual archives to life. For the first edition we’ve collaborated with the Harley-Davidson Museum, whose rich collection is a treasure trove for anyone interested in motorcycling, the history of this iconic American brand and even broader American culture and industry. With the help of Veo, we animated the Harley-Davidson Museum’s still archival imagery with subtle motion. You can switch easily between the original archival image and the AI video. See a glimpse of an old factory floor, board track racers or young people learning to ride. Gemini also generates insightful text and audio commentary for each animated photograph.“The Harley-Davidson Museum was immediately curious when the possibility of transforming our static collection photos into moving images came about,” says Bill Jackson, Manager of Archives and Heritage Services at the Harley-Davidson Museum. “Archival photos convey so much about people, their attitudes, determination and energy. When we see the people in motion, it adds more emotion and connection. We can never know some of these people in person, but these moving images help us feel one step closer.”Moving Archives is part of Google Arts & Culture’s commitment to exploring how advanced technologies can help anyone anywhere connect with art, history and culture in new ways. With our Artists in Residence program started in 2014, we’re supporting cultural institutions, creative coders and artists in experimenting with Google’s technologies and latest AI models, like using NotebookLM to make it easier to explore the ""American Lawn Tennis” magazine, or using Gemini to help co-compose a new piece of classical music.Explore Moving Archives and many more experiments from the Lab — spanning food, music, art, nature, travel, science and more — on Google Arts & Culture. POSTED IN: Arts & Culture AI",2025-07-01 13:00:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-04 04:49:16.594,2025-08-22 05:06:37.335,intermediate,"・プロジェクト概要：Google Arts & Culture Labは、Harley-Davidson Museumと協力し、AI技術を用いてアーカイブ写真を動画化する「Moving Archives」プロジェクトを実施した。VeoというAIツールを用いて、静止画に自然な動きを付加し、Geminiを用いて各写真に解説文と音声解説を生成した。これにより、歴史的な写真に新たな命を吹き込み、より感情的なつながりを生み出している
・技術的側面：Veoは、静止画に動きを与えるAI技術であり、微妙な動きを付加することで、写真に躍動感を与えている。Geminiは、多様なタスクに対応できるGoogleのAIモデルであり、写真の内容を理解し、それに基づいた解説文と音声解説を自動生成する役割を担っている。これらのAI技術の組み合わせにより、アーカイブ写真の活用方法に革新的なアプローチを提供している
・成果と影響：Harley-Davidson Museumのアーカイブ写真は、モーターサイクルの歴史、アメリカ文化、産業などを反映した貴重な資料である。Moving Archivesプロジェクトによって、これらの写真が動的なコンテンツに変換され、より多くの人々が歴史にアクセスし、理解を深めることができるようになった。静止画と動画の切り替えも容易で、ユーザー体験も向上している。博物館側も、静止画では伝えきれない感情や繋がりを、動画によって表現できるようになったと評価している
・今後の展望：Google Arts & Culture Labは、今後もAI技術を活用した文化遺産のデジタル化を進める予定である。Artists in Residenceプログラムなどを通して、文化機関やアーティストと連携し、AI技術の可能性を探求していく。本プロジェクトは、AI技術が文化遺産の保存と普及に貢献できることを示す成功例と言える",unified,8
cmdwms00q001mte68zepo11ry,Listen to a conversation about the newest AI capabilities in Search.,https://blog.google/products/search/release-notes-podcast-search/,Google AI: Release Notesポッドキャストで、Search製品担当VP Robby Steinが、Gemini 2.5 Pro、Deep Search、AIモードのマルチモーダル機能など、最新のAI機能によるGoogle Searchの進化について解説している。数億人があらゆる質問をできるようSearchを進化させる取り組みが紹介されている。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/release_notes_ep12_yt_thumbnail.max-1440x810.png,"The Keyword Home Product news Product news Android, Chrome & Play Android Chrome Chromebooks Google Play Wear OS See all Platforms & Devices Fitbit Google Nest Pixel See all Explore & Get Answers Gemini Maps News Search Shopping See all Connect & Communicate Classroom Photos Registry Translate In the Cloud Google Workspace More on the Cloud Blog Google Cloud See all See all product updates Company news Company news Outreach & initiatives Arts & Culture Education Entrepreneurs Public Policy Sustainability See all Technology AI Developers Health Google DeepMind Google Labs Safety and security See all Inside Google Data centers and infrastructure Doodles Googlers Life at Google See all Around the globe Google in Asia Google in Europe Google in Latin America See all Authors Sundar Pichai, CEO Demis Hassabis, CEO and Co-Founder, Google DeepMind Kent Walker, SVP James Manyika, SVP Ruth Porat, President & Chief Investment Officer See all Feed Press corner RSS feed Subscribe Breadcrumb Products Search What does it take to enable billions of people to truly ask anything in Search?In the latest episode of the Google AI: Release Notes podcast, host Logan Kilpatrick sits down with Robby Stein, VP of Product for Search, to discuss just that. They explore how we’re evolving Google Search with our latest capabilities — from the power of Gemini 2.5 Pro and Deep Search, to new multimodal features in AI Mode.Get the inside story by watching the full conversation below, or listen and subscribe on Apple Podcasts or Spotify. POSTED IN: Search AI Google DeepMind Related stories Let’s stay in touch. Get the latest news from Google in your inbox. Subscribe No thanks",2025-07-23 19:00:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-04 04:49:16.058,2025-08-22 05:06:37.335,intermediate,"・Gemini 2.5 ProとDeep Searchの活用：Google Searchは、Gemini 2.5 ProとDeep Searchの導入により、検索精度の向上とより複雑なクエリへの対応を実現している。これにより、従来のキーワード検索では得られなかった、より深いレベルでの情報検索が可能になった。具体的には、複雑な質問や曖昧な表現を含むクエリに対しても、正確で関連性の高い結果を提供できるようになった点が大きな進歩と言える。また、Deep Searchは、膨大なデータの中から関連性の高い情報を効率的に抽出することで、ユーザーにとってより価値のある検索結果を提供する役割を担っている
・AIモードにおけるマルチモーダル機能：AIモードは、テキストだけでなく画像や音声などのマルチモーダルな情報を活用した検索を可能にしている。これにより、ユーザーはより直感的で自然な方法で情報を検索できるようになった。例えば、画像をアップロードして類似画像を検索したり、音声で質問することで、テキスト入力に比べてより効率的に情報を得ることができる。このマルチモーダル機能は、ユーザーエクスペリエンスを大幅に向上させ、検索の敷居を下げる効果が期待される
・数億人へのアクセス可能性の追求：このポッドキャストでは、数億人規模のユーザーがGoogle Searchを通じてあらゆる質問をできるよう、技術開発を進めていることが強調されている。これは、単に検索機能の向上だけでなく、アクセシビリティの向上やグローバルな情報へのアクセス機会の拡大といった、より広範な社会貢献を目指す取り組みと言える。そのため、多言語対応や様々なデバイスへの対応など、幅広い技術開発が背景にあると考えられる
・ポッドキャストの内容と入手方法：Google AI: Release Notesポッドキャストで、Search製品担当VP Robby Steinが、Google Searchの最新のAI機能について詳細に解説している。このポッドキャストは、Apple PodcastsやSpotifyなどで視聴・購読可能であり、動画版も公開されている。ポッドキャストでは、技術的な詳細だけでなく、開発の背景や今後の展望なども語られているため、Google Searchの進化を理解する上で非常に有益な情報源となる",unified,8
cmdwms0bp003jte685z420erd,How Lush and Google Cloud AI are reinventing retail checkout,https://blog.google/around-the-globe/google-europe/united-kingdom/how-lush-and-google-cloud-ai-are-reinventing-retail-checkout/,LushはGoogle Cloud AIを活用し、包装されていない商品を瞬時に識別するレジシステムを導入、チェックアウト時間を大幅に短縮し効率性を向上させた。これは持続可能性を重視する同社の理念と顧客体験、従業員研修の改善に貢献している。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/lush_lens_storyboard_photo__2_1.width-1300.jpg,"Breadcrumb Around the Globe Google in Europe United Kingdom How Lush and Google Cloud AI are reinventing retail checkout Jul 09, 2025 · Share Twitter Facebook LinkedIn Mail Copy link Lush revolutionizes retail with Google Cloud AI to power in-store tills that instantly identify unpackaged products, drastically cutting checkout times and boosting efficiency. This sustainable solution improves customer experience and employee onboarding. Mark Steel Director, Global Strategic Industries, Retail & Consumer, EMEA Share Twitter Facebook LinkedIn Mail Copy link Lush is known for its vibrant, fragrant, and ever growing range of packaging-free cosmetics. These ‘naked’ products, like their iconic bath bombs and shampoo bars, are great for the planet but create a unique challenge at the checkout: how do you scan an item that has no barcode?Previously, staff had to memorize hundreds of products to manually enter them at the till. This led to slower transactions and long lines, especially during busy seasons. To solve this, Lush decided to bring the AI from its popular Lush Lens app feature—which lets customers scan products with their phones—directly to its in-store tills, all powered by Google Cloud.Using Google Cloud Storage to host a library of over half a million product images and built with Gemini via Google Cloud’s Vertex AI platform, to train its recognition model, Lush tills can now instantly identify any unpackaged product held up to the camera. What was once a manual lookup is now a split-second scan.The results are transforming the store experience. According to Lush staff, during the Christmas peak in Glasgow queue times dramatically reduced from out-the-door to around just three minutes thanks to Lush Lens on the tills.Beyond shorter lines, the AI-driven system has delivered powerful benefits. By creating a more efficient and digital-first process, Lush has:Saved 440,000 liters of water by reducing the need for in-store product demonstrations.Significantly shortened onboarding time for new employees, making the workplace more inclusive.Improved billing accuracy and inventory management through precise, AI-driven identification.Lush's story shows how AI can support a company's core mission—in this case, sustainability—while improving efficiency and creating a better experience for customers and employees alike. By embracing technology, Lush isn't just selling cosmetics; it's designing a smarter, more sustainable future for retail.To learn more about how retail companies are innovating, visit https://cloud.google.com/solutions/retail POSTED IN: Google Cloud AI Sustainability",2025-07-09 08:00:00,cmdwmplco0001tec833nye4ak,0,60,0,2025-08-04 04:49:16.454,2025-08-22 05:06:37.383,intermediate,"・AIによる商品識別システム：Google Cloud Storageに50万点以上の商品画像を保存し、GeminiとVertex AIを用いてAIモデルを構築。これにより、バーコードのない商品もカメラにかざすだけで瞬時に識別可能となり、手動入力による遅延を解消した。クリスマス時期のグラスゴー店では、待ち時間が大幅に短縮されたと報告されている
・持続可能性への貢献：AIシステム導入により、店内での商品実演の減少を通して約44万リットルの水の節約に成功。これはLushの持続可能性への取り組みを強力に支援している
・従業員研修の効率化：従来、数百種類の商品を暗記する必要があった従業員研修が大幅に簡素化され、オンボーディング時間が短縮された。これにより、より多くの従業員を採用し、職場環境の多様化を促進できるようになった
・業務効率の向上と精度の改善：AIによる正確な商品識別は、請求精度の向上と在庫管理の最適化に繋がっている。これにより、ビジネス全体における効率性が向上し、コスト削減にも貢献している",unified,8
cmdwmrzvw000gte68fps6jrp4,The inside story of building NotebookLM,https://blog.google/technology/ai/developing-notebooklm/,Google LabsのNotebookLMは、研究、思考、執筆を支援するアプリとして開発された。ユーザーのソースを基に情報を合成し、簡潔な理解を促進する。初期プロトタイプは6週間で開発され、ユーザーフィードバックを基に機能追加を繰り返し、現在では80以上の言語に対応したAudio Overviewsやモバイルアプリを提供している。継続的な改善とユーザー重視の開発により、大きな成功を収めている。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/NotebookLM_story_ss.width-1300.png,"In mid 2022, a small team within Google Labs had a big idea: an app that would deploy our advanced language models to help people with research, thinking and writing, all grounded in sources they had on hand. Trawling through the docs and slides and links you deemed relevant to a project, it would helpfully find and synthesize the info you needed. Then known as Project Tailwind, it would be released the following July as NotebookLM.“The first prototype was built in six weeks, with four to five people working on it part-time,” says Steven Johnson, who’s been on NotebookLM since those early days. “But the potential was clear from the beginning.” Two years later, that potential is being realized. NotebookLM has been one of our breakout AI successes, helping everyone from researchers trying to make sense of piles of papers, to college students corralling sources for a thesis and generating study guides.“One of the reasons NotebookLM has been so successful is the simplicity of the creation process,” says Ani Mohan, group product manager on NotebookLM. “You have all these interesting sources in front of you and don't need to think very hard about what to make. You can just turn whatever's in front of you into something even more helpful for learning and understanding.”Another reason? The team hasn’t stopped working to improve it. ""Our team always says we’re aiming for the intersection point of the newly magical and the actually useful,” Steven says. ""We look at both the amazing new things that are possible with AI, but also listen closely to our users to figure out what’s most helpful for them.”The original version of NotebookLM — then known as “Project Tailwind” — when it was first announced at Google I/O in 2023.The team has been soliciting feedback on NotebookLM since before launch, including with internal testing and a company-wide chat. Tens of thousands of monthly active users inside Google are using notebooks to help make sense of meeting transcriptions, manage their own notes and ideas and even parse through lengthy interviews when drafting stories.“It's exciting to see so much NotebookLM usage inside the company,” Ani says. “It makes it a lot easier for us to quickly get feedback on new features and make sure we're building an increasingly valuable product for Googlers and the world at large.”To that end, the team has also created in-app forms for users to share their experience and suggest features. When NotebookLM first launched, they even set up a Discord server to talk directly to people who were using it.These conversations sparked the first new features the team would add, like the ability to save responses as notes, using Gemini to auto-suggest questions based on the sources and in-line citations. “It was clear to people that we were really listening to them,” Steven says. “Things they asked for would show up in our product roadmaps, making NotebookLM more useful to them and their specific needs.”Google Labs & Gemini VP Josh Woodward demonstrating Audio Overviews at Google I/O 2024.Last September, we launched Audio Overviews, which synthesize your sources into a podcast-style conversation between two AI “hosts.” And as users began listening on NotebookLM, we continued to listen to them.“From the beginning, people were asking for Audio Overviews support in other languages,” Ani says. “We were initially only planning four new languages: Hindi, Japanese, Korean and Spanish. But in a very pleasant surprise — as often happens when we work with Google DeepMind — the research team discovered that the models work in way more languages. And so we went from four to 10 to 20 to 50 to 80.”When the team added more than 80 languages to the feature this April, the number of Audio Overviews created each day doubled in just two weeks. And the number of total users doubled just a few weeks later, when the team launched the mobile app for NotebookLM just ahead of I/O — another key user request. “We're now meeting users where they spend a lot of time every day — we’re seeing more and more Audio Overviews created on mobile,” Ani says.The team also recently introduced the ability to choose your own ideal length for Audio Overviews, a quick way to share notebooks publicly and today, the launch of Video Overviews.“NotebookLM has gotten this far by listening to our users and evolving based on feedback,” says Steven. “Whether it's six Googlers chatting to our users in a forum, or dozens of people working to create a new feature, we’re excited to keep building a tool to help people understand anything. Keep the feedback coming!”",2025-07-29 16:00:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-04 04:49:15.884,2025-08-22 05:06:37.433,intermediate,"・開発経緯と初期段階：NotebookLM（旧称Project Tailwind）は、Google Labsの少人数チームが2022年中頃に構想し、6週間で最初のプロトタイプを開発した。当初は社内テストと社内チャットを通じてフィードバックを集め、数万人の月間アクティブユーザーを獲得した。初期段階からユーザーのニーズを重視した開発が成功の鍵となった
・ユーザーフィードバックと機能追加：ローンチ前から社内ユーザーからのフィードバックを積極的に収集し、Discordサーバーも活用した。ユーザーからの要望に基づき、回答のメモ保存機能、Geminiによる質問自動提案機能、インライン引用機能などを追加した。これは、ユーザーからのフィードバックを製品ロードマップに反映することで、製品の有用性を高めた好例である
・Audio Overviewsの開発と多言語対応：2023年9月に導入されたAudio Overviewsは、ソースをポッドキャスト形式で要約する機能である。当初は4言語の対応を予定していたが、Google DeepMindとの連携により、80以上の言語に対応できることが判明し、迅速に多言語化を実現した。この機能追加により、ユーザー数とAudio Overviewsの作成数が大幅に増加した
・モバイルアプリとVideo Overviewsのリリース：ユーザーからの要望に応え、2024年のGoogle I/O直前にモバイルアプリをリリースした。これにより、モバイル環境でのAudio Overviews作成が増加し、ユーザーの利便性が向上した。さらに、Audio Overviewsの長さ選択機能、ノートの公開共有機能、そして最新のVideo Overviews機能も追加された
・成功要因と今後の展望：NotebookLMの成功要因は、ユーザーからのフィードバックを重視した継続的な改善と、ユーザーニーズへの迅速な対応にある。  Googleは、ユーザーからのフィードバックを継続的に収集し、NotebookLMをさらに進化させていく計画である",unified,8
cmec08paj003ate8a2bhfovf8,5 Chrome features I use all the time as a college student,https://blog.google/products/chrome/chrome-features-students/,大学生が常に使用するChromeの5つの機能を紹介している。学習効率の向上、整理整頓、集中力の維持に役立つChromeの機能とヒントを提供することで、学生生活を支援することを目的とする。具体的な機能名は本文には記載されていないため、詳細は不明だが、生産性向上に繋がるChromeの機能が紹介されていると推測できる。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Chromebacktoschool_Hero.max-600x600.format-webp.webp,"<img src=""https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Chromebacktoschool_Hero.max-600x600.format-webp.webp"">These Chrome features and tips for students can help you learn more easily while staying organized and focused, too.",2025-08-14 16:00:00,cmdwmplco0001tec833nye4ak,0,59,0,2025-08-14 23:02:42.955,2025-08-22 05:06:37.433,intermediate,"・Chrome機能の概要：記事は大学生向けのChromeの便利な5つの機能を紹介している。具体的な機能名は明記されていないものの、学習効率の向上、整理整頓、集中力の維持に役立つ機能であることが示唆されている。これらの機能を活用することで、学生はより効果的に学習に取り組むことができると考えられる。
・記事の目的：本記事の目的は、大学生が学習効率を向上させ、整理整頓された状態を維持し、集中力を高めるためのChromeの機能とヒントを提供することにある。より効果的な学習方法を提案することで、学生の学習環境の改善に貢献することを目指している。
・記事の構成：記事は画像と共に、大学生が日常的に利用するChromeの5つの機能を簡潔に紹介している。各機能の詳細な説明や使用方法については触れられていないが、機能のメリットを端的に示すことで、読者の興味を引く構成となっている。具体的な機能名は不明だが、生産性向上に繋がる機能であると推測できる。",unified,8
cmdwms07i002lte68ro0gftpa,Google France hosted a hackathon to tackle healthcare's biggest challenges,https://blog.google/technology/health/google-france-ai-healthcare-hackathon/,Googleフランスは、医療分野の課題解決を目指すハッカソンを開催した。130名の専門家がGoogleのオープンAIモデルを用いて、救急医療のトリアージ改善や腫瘍患者支援など、様々な医療プロトタイプを開発した。POIG(がん治療支援AI)、VitalCue(スマートウォッチデータ活用アプリ)、AURA(救急医療AIアシスタント)などが受賞作品として紹介され、AIによる医療の進歩を示した。Google.orgは欧州の医療AI推進のため500万ドルの支援を発表した。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Google_France_Hackathon.width-1300.png,"Breadcrumb Technology Health Google France hosted a hackathon to tackle healthcare's biggest challenges Share Twitter Facebook LinkedIn Mail Copy link Doctors, developers and researchers gathered in Paris to prototype new medical solutions using Google’s AI models. Joelle Barral Senior Director of Research & Engineering, Google DeepMind Share Twitter Facebook LinkedIn Mail Copy link From improving clinical trials to easing administrative workloads, AI is already changing what's possible in healthcare. To help accelerate this progress, Google France recently brought together 130 experts for a 12-hour hackathon focused on building new medical prototypes using open AI models.Twenty-six teams used Google's open models — including Gemma, MedGemma and TxGemma — to develop functional prototypes addressing challenges that ranged from improving emergency-room triage to providing better support for oncology patients.The ingenuity on display reflects a wider movement across Europe to apply AI to medicine and life sciences. To support this movement, Google.org announced a $5 million commitment to organizations using AI to advance European healthcare. This initiative will help local organizations and professionals build stronger digital health ecosystems. The hackathon explored a wide range of potential solutions. Here are the winning projects that showcase howGoogle's open models can help solve pressing healthcare challenges:1st Place: POIG (Precision Oncology Interface Gemma) is an AI system designed to support the complex decision-making process in oncology. The project demonstrated a scalable solution to a critical need with significant potential for patient impact. Team: Arun Nadarasa, Jonas Gottal, Juraj Vladika, Mohamad Ammar Said, Nathan Brahmbhatt, William Gehin2nd Place: VitalCue transforms smartwatch health data into actionable insights using Gemma. The application helps users identify early signs of health issues, supporting preventative care. Team: Martin Maritsch, Nathan Denier, Nour Ben Rejeb, Patrick Langer3rd Place: AURA is an AI assistant that provides instant, objective triage insights for hospital emergency staff. Built with MedGemma and Vertex AI, it is designed to ease physician burden and reduce wait times. Team: Soufiane Lemqari, Leo Cartel, Laura Sibony, Vyacheslav EfimovHonorable Mention: IGT Assist is a voice-controlled solution using MedGemma that allows surgeons to manipulate medical images during procedures. Team: Aymeric Lamboley, Kondracki Maxim, Rahma Ait Ouaret, Safae HaririHonorable Mention: Owma is a platform for biomedical researchers that uses multimodal models to integrate diverse patient data — including cutting-edge spatial transcriptomics — to help accelerate oncology research. Team: Barbara Bodinier, Nathan Bigaud, Pierre-Antoine Bannier, Vincent CabeliThese projects offer a glimpse into how open models and collaborative innovation can create tangible improvements in healthcare. By supporting the physicians, developers, researchers and organizations behind these ideas, we can help turn powerful concepts into real-world solutions. POSTED IN: Health AI Google in Europe",2025-07-16 09:47:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-04 04:49:16.302,2025-08-22 05:06:37.479,intermediate,"・ハッカソン概要：Googleフランスは、医療分野におけるAI活用促進のため、130名の医師、開発者、研究者を集め、12時間にわたるハッカソンを開催した。Gemma、MedGemma、TxGemmaなどのGoogleのオープンAIモデルが使用され、26チームが様々な医療課題への解決策となるプロトタイプを開発した。これは、欧州におけるAIと医療・生命科学の融合を促進する動きの一環である
・受賞プロジェクト：1位は、がん治療における意思決定を支援するAIシステム「POIG」。2位は、スマートウォッチの健康データを活用し、健康問題の早期発見を支援するアプリ「VitalCue」。3位は、救急医療現場におけるトリアージを支援するAIアシスタント「AURA」。その他、手術支援システム「IGT Assist」や、バイオメディカル研究プラットフォーム「Owma」などが表彰された。これらのプロジェクトは、オープンモデルと協調的イノベーションが医療における具体的な改善をもたらす可能性を示している
・Google.orgの支援：Google.orgは、欧州の医療におけるAI活用を推進するため、関連団体に500万ドルの支援を行うことを発表した。この取り組みは、地域組織や専門家がより強力なデジタルヘルスエコシステムを構築するのに役立つと期待されている
・ハッカソンの成果と意義：今回のハッカソンは、GoogleのオープンAIモデルが医療分野の様々な課題解決に役立つことを実証した。医師、開発者、研究者間の協働により、革新的な医療ソリューションが生まれた。この取り組みは、AIを活用した医療の進歩を加速させる上で重要な役割を果たすと考えられる
・今後の展望：Googleは、今後もオープンAIモデルの提供や支援を通じて、医療分野におけるAI活用を促進していく姿勢を示している。今回のハッカソンの成果は、今後の医療技術開発における重要な指針となるだろう。AIによる医療の進化は、より質の高い医療サービスの提供につながることが期待される",unified,8
cmdwms0d2003tte68kwx0x0na,New AI tools for mental health research and treatment,https://blog.google/technology/health/new-mental-health-ai-tools-research-treatment/,Googleは、AIを活用したメンタルヘルスケア研究と治療のための2つの新イニシアチブを発表した。1つは、AIによるエビデンスに基づいた介入拡大のための現場ガイド、もう1つは、不安、うつ病、精神病の治療におけるAI研究への多額の投資である。これにより、質の高いメンタルヘルスケアへのアクセスを民主化し、より精密で個別化された治療法の開発を目指す。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AI_for_Mental_Health_social-share.width-1300.png,"Breadcrumb Technology Health New AI tools for mental health research and treatment Jul 07, 2025 · Share Twitter Facebook LinkedIn Mail Copy link This field guide and investment support AI’s potential in evidence-based mental health interventions and research Dr. Megan Jones Bell Clinical Director, Consumer and Mental Health Share Twitter Facebook LinkedIn Mail Copy link Today, we’re announcing two new initiatives to explore how AI can support experts in providing better mental health treatment and help people receive much-needed care. Billions of people worldwide face untreated mental health conditions, particularly in low- and middle-income countries. To help, we’re exploring AI-based solutions that can democratize access to quality, evidence-based support.The first initiative is a practical field guide for mental health organizations on how to use AI for scaling evidence-based mental health interventions, created in partnership with Grand Challenges Canada and McKinsey Health Institute. This guide offers foundational concepts, use cases and considerations for using AI responsibly in mental health treatment, including for enhancing clinician training, personalizing support, streamlining workflows and improving data collection.For the second initiative, Google for Health and Google DeepMind have partnered with Wellcome Trust, one of the largest charities in the world, on a multi-year investment in AI research for treating anxiety, depression and psychosis. The funding, which includes research grant funding from the Wellcome Trust, will support research projects to develop more precise, objective and personalized ways to measure nuances of these conditions, and explore new therapeutic interventions for them, potentially including novel medications.Together, these initiatives make up a two-pronged approach. By looking into AI’s potential for more immediate mental health support, along with developing better treatments for the future, we hope to help more people around the world find the care they need. POSTED IN: Health Google.org Nonprofits AI",2025-07-07 19:00:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-04 04:49:16.502,2025-08-22 05:06:37.479,intermediate,"・現場ガイドの提供：Google、Grand Challenges Canada、McKinsey Health Instituteが共同で作成した現場ガイドは、メンタルヘルス組織がAIを効果的に活用するための指針を提供する。AIによる臨床医トレーニングの強化、個別化されたサポートの提供、ワークフローの合理化、データ収集の改善といったユースケースと、責任あるAI利用のための考慮事項が網羅されている。具体的には、AIを活用したメンタルヘルス介入のスケーラビリティ向上のための具体的なステップや、倫理的な考慮事項、データプライバシーに関するベストプラクティスなどが記述されていると考えられる
・AI研究への多額投資：Google for Health、Google DeepMind、Wellcome Trustによる複数年にわたる共同投資は、不安、うつ病、精神病の治療におけるAI研究を支援する。この投資は、これらの疾患の微妙なニュアンスをより正確かつ客観的に測定し、新しい治療法（新規薬剤を含む可能性がある）を探求するための研究プロジェクトを支援する。具体的な研究内容としては、脳波や生理学的指標などのデータを用いた疾患の客観的評価、AIによるパーソナライズされた治療法の開発、AIを用いた新規薬剤候補の探索などが含まれると考えられる
・世界的なメンタルヘルスケアへの貢献：これらのイニシアチブは、AIによる即効性のあるメンタルヘルスサポートと将来的な治療法開発の両面からアプローチすることで、世界中のより多くの人々が必要なケアを受けられるようにすることを目指している。特に低・中所得国におけるメンタルヘルスケアへのアクセス向上に貢献することが期待される。具体的な数値目標は提示されていないものの、世界規模でのメンタルヘルス問題への対応という大きな目標を掲げている
・多様なパートナーシップ：本イニシアチブは、Google、Grand Challenges Canada、McKinsey Health Institute、Wellcome Trustなど、多様な分野の専門機関とのパートナーシップによって実現している。それぞれの機関が持つ専門知識やリソースを統合することで、より効果的で包括的なアプローチが可能となる。このパートナーシップは、AI技術の開発と社会実装における協調体制の重要性を示している",unified,8
cmdwms0ai003ate687et4paaz,Dive deeper with AI Mode and get gaming help in Circle to Search,https://blog.google/products/search/circle-to-search-ai-mode-gaming/,GoogleはCircle to SearchにAIモードとモバイルゲームヘルプを追加した。AIモードにより、アプリを切り替えることなく複雑なトピックを深く探求できる。モバイルゲーム中に、ゲームヘルプも利用可能となり、攻略法などを検索できる。AIの概要表示も改善され、より読みやすく、視覚情報も豊富になった。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DiveDeeper_CircletoSearch_Hero_vfinal.width-1300.png,"Breadcrumb Products Search Dive deeper with AI Mode and get gaming help in Circle to Search Jul 09, 2025 · Share Twitter Facebook LinkedIn Mail Copy link We’re bringing the capabilities of AI Mode to Circle to Search so you can ask follow-up questions and dive deeper on the web. And we’re adding mobile gaming help directly in Circle to Search. Harsh Kharbanda Director, Product Management, Search Read AI-generated summary General summary Circle to Search is now on over 300 million Android devices. You can now use AI Mode within Circle to Search to explore complex topics without switching apps. Also, gamers can now get help within mobile games using Circle to Search. Summaries were generated by Google AI. Generative AI is experimental. Basic explainer Circle to Search helps you find stuff on your phone without leaving the app you're using. Now, it has a new AI Mode that lets you ask more questions about what you find. It can also help you with games by giving you tips and tricks. Plus, the AI Overviews are now easier to read and have more pictures. Summaries were generated by Google AI. Generative AI is experimental. Explore other styles: General summary Basic explainer Share Twitter Facebook LinkedIn Mail Copy link Since we introduced Circle to Search last year, people have been using it to circle, highlight, or tap on their Android devices to quickly get more information and additional AI insights from across the web, without switching apps. And now, we’re excited to share that Circle to Search is available on more than 300 million Android devices.Today, we’re bringing advanced new capabilities to Circle to Search, making it even easier to explore information and get quick help precisely when you need it most.Circle, search and dive deeper in AI ModeWe’re bringing our most powerful AI search experience, AI Mode, right into Circle to Search. This means you can now access AI Mode’s advanced reasoning to explore complex topics and dig into your initial searches with follow-up questions – all without switching apps. Simply long press the home button or navigation bar, then circle, tap, or gesture on what you want to search. When our systems determine an AI response to be most helpful, an AI Overview will appear in your results. From there, scroll to the bottom and tap “dive deeper with AI Mode” to ask follow-up questions and explore content across the web that’s relevant to your visual search.We’re also making it possible to access AI Mode through Lens, via the Google app (Android and iOS). So no matter where you’re asking for help with your multimodal questions, AI Mode can provide deeper insights. Try it today in the U.S. and India where AI Mode is available.Get gaming help when you need it mostYou can already use Circle to Search to search for music, translate in real-time and get helpful AI responses to your device’s screen. Starting today, you can get in-the-moment help with Circle to Search while gaming on mobile. Need to identify a new character or find a winning strategy? Get the tips you need without leaving your game, helping you get unstuck and keep the action going. Long press on the home button or navigation bar on your Android device to activate Circle to Search. Then simply circle or tap to see an AI Overview with information about what’s on your screen, including suggested videos to help you even further navigate your game. This is available today in countries where AI Overviews are available.See the bigger picture with upgraded AI OverviewsBack in January, we expanded AI Overviews to more kinds of visual searches. Thanks to advancements in our latest Gemini models, we continue to upgrade AI Overviews so they’re even more helpful. Now, you’ll see that responses are easier to read, breaking down key information, and incorporating more visuals directly into the responses, so you can get even more context, right when you need it. POSTED IN: Search AI",2025-07-09 14:00:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-04 04:49:16.411,2025-08-22 05:06:37.479,intermediate,"・AIモードの統合：Circle to SearchにAIモードが統合されたことで、アプリを切り替えることなく、複雑なトピックに関するフォローアップ質問を行い、ウェブ上の情報を深く掘り下げることができるようになった。長押しでホームボタンまたはナビゲーションバーを起動し、検索したい部分を囲む、タップ、またはジェスチャーを行うことで、AIによる回答が提供される。AIの概要表示の下部にある「AIモードで詳しく調べる」をタップすることで、フォローアップ質問を行い、関連するコンテンツを探求できる。この機能は、米国とインドで利用可能
・モバイルゲームヘルプの追加：Circle to Searchで、モバイルゲーム中にリアルタイムでヘルプを受けられるようになった。新しいキャラクターの特定や勝利戦略の発見など、ゲームを中断することなくヒントを得ることができる。ホームボタンまたはナビゲーションバーを長押ししてCircle to Searchを起動し、囲むかタップすることで、画面上の情報を含むAIの概要表示が表示され、さらにゲームをナビゲートするための動画も提案される。AIの概要表示が利用可能な国で利用可能
・AI概要表示の改善：AI概要表示が改善され、Geminiモデルの進歩により、より読みやすく、重要な情報が明確に示され、視覚情報も豊富になった。これにより、必要な情報をより多くのコンテキストと共に取得できるようになった
・Circle to Searchの普及：Circle to Searchは3億台以上のAndroidデバイスで利用可能になった。これは、アプリを切り替えることなく、デバイス上の情報を素早く取得し、追加のAIインサイトを得るために、ユーザーがCircle、ハイライト、またはタップを使用していることを示している
・機能概要：Circle to Searchは、使用中のアプリを離れることなく、デバイス上の情報を検索できる機能である。今回のアップデートでは、AIモードの追加、モバイルゲームヘルプの追加、AI概要表示の改善が行われた。これにより、ユーザーはより効率的に情報を検索し、ゲームプレイを支援することができるようになった",unified,8
cmdxpr48k001vtezp6p34oz9h,Rethinking how we measure AI intelligence,https://blog.google/technology/ai/kaggle-game-arena/,Kaggle Game Arenaは、AIモデルの能力を評価する新しいベンチマークプラットフォームです。戦略ゲームを用いたヘッドツーヘッド対戦により、モデルの戦略的推論、長期計画、動的適応能力を客観的に評価します。オープンソースのゲーム環境と評価システムにより、公平で透明性の高い評価を実現し、AIの発展に貢献します。8月5日にはチェス競技会を開催し、その成果を公開します。将来的にはGoやポーカーなど、様々なゲームへの展開を予定しています。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Kaggle_SocialShare.width-1300.png,"Current AI benchmarks are struggling to keep pace with modern models. As helpful as they are to measure model performance on specific tasks, it can be hard to know if models trained on internet data are actually solving problems or just remembering answers they've already seen. As models reach closer to 100% on certain benchmarks, they also become less effective at revealing meaningful performance differences. We continue to invest in new and more challenging benchmarks, but on the path to general intelligence, we need to continue to look for new ways to evaluate. The more recent shift towards dynamic, human-judged testing solves these issues of memorization and saturation, but in turn, creates new difficulties stemming from the inherent subjectivity of human preferences.While we continue to evolve and pursue current AI benchmarks, we’re also consistently looking to test new approaches to evaluating models. That’s why today, we're introducing the Kaggle Game Arena: a new, public AI benchmarking platform where AI models compete head-to-head in strategic games, providing a verifiable, and dynamic measure of their capabilities.Why games are a meaningful evaluation benchmarkGames provide a clear, unambiguous signal of success. Their structured nature and measurable outcomes make them the perfect testbed for evaluating models and agents. They force models to demonstrate many skills including strategic reasoning, long-term planning and dynamic adaptation against an intelligent opponent, providing a robust signal of their general problem-solving intelligence. The value of games as a benchmark is further enhanced by their scalability—difficulty increases with the opponent's intelligence—and by our ability to inspect and visualize a model's ""reasoning,"" which offers a glimpse into its strategic thought process.Specialized engines like Stockfish and general game playing AI models like AlphaZero have been able to play games at a superhuman level for many years and would beat every frontier model without a doubt. Today’s large language models, however, are not built to specialize in any specific games, and as a result they do not play them nearly as well. While the immediate challenge for the models is to close this gap, in the long-term we would hope for them to achieve a level of play beyond what is currently possible. And with an endlessly increasing set of novel environments we can continue to challenge them even further.How Game Arena promotes fair and open evaluationGame Arena is built on Kaggle to provide a fair, standardized environment for model evaluation. For transparency, game harnesses — the frameworks that connect each AI model to the game environment and enforce the rules — as well as the game environments are all open-sourced. Final rankings are determined by a rigorous all-play-all system, where an extensive number of matches between each model pair ensures a statistically robust result.Google DeepMind has long used games as a benchmark, from Atari to AlphaGo and AlphaStar, to demonstrate complex AI capabilities. By testing these models in a competitive arena, we can establish a clear baseline for their strategic reasoning and track progress. The goal is to build an ever-expanding benchmark that grows in difficulty as models face tougher competition. Over time, this could lead to novel strategies, much like AlphaGo's famous and creative “Move 37” that baffled human experts. The ability to plan, adapt and reason under pressure in a game is analogous to the thinking needed to solve complex challenges in science and business.How you can watch the chess exhibition matchesOn August 5 at 10:30 a.m. Pacific Time, join us for a special chess exhibition where eight frontier models will face off in a single elimination showdown. We selected a sample from the matches for this exhibition. Hosted by the world's best chess experts, this event is the premiere demonstration of the Game Arena methodology.While the fun exhibition matches are in a tournament format, the final leaderboard rankings will be determined by the all-play-all system and released after the exhibition. This more extensive method runs over a hundred matches between every pair of models to ensure a statistically robust and definitive measure of performance. You can find more details and how to watch the games at kaggle.com/game-arena.We plan to run more tournaments in the future on a regular basis, more on that soon.How we’re building the future of AI benchmarksThis is only the beginning. Our vision for the Game Arena extends far beyond a single game. Kaggle will soon expand Game Arena with new challenges, starting with classics like Go and poker. These games, along with future additions like video games, are excellent tests of AI’s ability to perform long-horizon planning and reasoning, helping us create a comprehensive and ever-evolving benchmark for AI. We’re committed to continuously adding new models and harnesses to the mix, pushing the boundaries of what AI models can achieve. For more details about the Game Arena and the inaugural chess exhibition tournament, see Kaggle’s blog post.",2025-08-04 16:00:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-04 23:00:19.893,2025-08-22 05:06:37.528,intermediate,"・Kaggle Game Arenaの概要：Kaggle上に構築された新しいAIベンチマークプラットフォームで、AIモデルが戦略ゲームで対戦し、その能力を評価する。オープンソースのゲーム環境と評価システムにより、公平で透明性の高い評価を実現。従来のベンチマークの限界（過学習、飽和）を克服し、より包括的なAI能力の評価を目指す
・ゲームを用いた評価の意義：ゲームは成功/失敗が明確で、戦略的推論、長期計画、動的適応などの能力を総合的に評価できる。対戦相手の知能に応じて難易度が調整できるため、スケーラビリティにも優れる。モデルの思考過程を可視化できる点も大きな利点。StockfishやAlphaZeroのような既存の高度なゲームAIと比較することで、大規模言語モデルなどの進歩を客観的に測れる
・公平で開かれた評価：Kaggleを利用することで、標準化された公平な評価環境を提供。ゲームハーネスとゲーム環境はオープンソース化され、透明性を確保。全ペア対戦によるランキング決定で統計的に堅牢な結果を得る。Google DeepMindのこれまでのゲームAI研究（Atari、AlphaGo、AlphaStar）を踏襲し、競争的な環境でAI能力を評価する
・チェス競技会：8月5日10時30分（太平洋時間）に、8つの最先端モデルによるチェス競技会を開催。トーナメント形式で行われ、世界トップレベルのチェス専門家が解説を行う。最終的なランキングは、全ペア対戦によるより広範な評価に基づいて決定され、競技会後発表される。Kaggle.com/game-arenaで詳細を確認できる
・将来展望：将来的にはGo、ポーカーなどのゲーム、さらにはビデオゲームへの展開を計画。長期計画と推論能力を評価する包括的で進化するベンチマークを目指し、新たなモデルやハーネスを追加することで、AIの限界を押し広げる
・技術的詳細：全ペア対戦システムによるランキング決定は、各モデル間の多数の対戦（数百試合）を実施することで、統計的に信頼性の高い結果を得ることを目的とする。オープンソース化されたゲームハーネスは、AIモデルとゲーム環境を接続し、ルールを強制する役割を果たす。これにより、評価プロセスの透明性と再現性を高める",unified,8
cmdwmrzwv000ote68d2eg1hrq,New ways to learn and explore with AI Mode in Search,https://blog.google/products/search/ai-mode-updates-back-to-school/,Google検索のAIモードが、バック・トゥ・スクールシーズンに合わせて機能強化された。画像・PDFへの質問対応（Googleドライブ対応も予定）、計画作成支援機能「Canvas」、動画入力によるリアルタイムヘルプ「Search Live」などが追加された。これにより、複雑な質問への回答や質の高い情報探索が容易になり、学習効率の向上に貢献する。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/LearnandExplorewithAIMode_SS.width-1300.png,"Breadcrumb Products Search New ways to learn and explore with AI Mode in Search Jul 29, 2025 · Share Twitter Facebook LinkedIn Mail Copy link AI Mode is getting more helpful just in time for back to school, with Canvas for planning, Search Live with video, PDF uploads and more. Robby Stein VP of Product, Google Search Read AI-generated summary General summary Google Search is launching new AI Mode features to help you learn. You can now ask questions about images and PDFs, and soon files from Google Drive. Also, try the Canvas feature to build plans and organize information, and Search Live with video input for real-time help. Summaries were generated by Google AI. Generative AI is experimental. Share Twitter Facebook LinkedIn Mail Copy link We’re introducing new features and capabilities for AI Mode in Search, just in time for the back-to-school season. Whether you’re a student, a parent or an educator — or just wrapping up a busy summer — AI Mode can help you explore complex questions and discover high-quality information from across the web. To get started today on desktop, look for the new AI Mode button on the Google homepage.Ask questions about images and PDFsYou can already use AI Mode in the Google app on Android and iOS to ask complex questions about images, and this week the same capability is launching on desktop browsers. Plus, in the coming weeks, we’re adding support for PDF uploads on desktop, so you can ask detailed questions about those documents and bring that context into your search.For example, you could upload PDF slides from your psychology lecture and ask follow-up questions to deepen your understanding beyond the primary course materials. Results for illustrative purposes and may vary. Available in the US and India, in English, and to users 18+. AI Mode will analyze the contents of your file and cross-reference it with relevant information from the web to provide a helpful AI response, along with prominent links so you can dig deeper.In the months ahead, AI Mode will support additional file types beyond PDFs and images, including files from your Google Drive.Make a (study) plan with CanvasWhen you’re staring down a big project or task, staying organized and keeping track of information from different places can be challenging. That’s where the new Canvas feature in AI Mode can help.With Canvas, you can build plans and organize information over multiple sessions in a dynamic side panel that updates as you go. For example, if you want to create a study plan for an upcoming test, just ask AI Mode, then tap on the “Create Canvas” button to get started. Results for illustrative purposes and may vary. Available in the US, in English, and to users 18+ in Labs. Right away, AI Mode will start piecing everything together in the Canvas side panel, and you can use follow-ups to refine the output until it meets your exact requirements. Soon, the new upload feature will also make it possible to customize your study guide (or whatever you need to create) with context from your files, like class notes or a course syllabus.No matter what you're working on, from test prep to travel planning, you can always come back to your Canvas project and pick up where you left off.In the coming weeks, users enrolled in the AI Mode Labs experiment in the U.S. will begin to see Canvas on desktop browsers. Just look for the “Create Canvas” option that appears when you ask for help creating or planning something.Get real-time help with Search LiveThis week, we’re rolling out Search Live with video input, bringing advanced capabilities from Project Astra directly into AI Mode. When you go Live with Search, it’s like having an expert on speed dial who can see what you see and talk through tricky concepts in real-time, all with easy access to helpful links on the web. Search Live is fully integrated with Google Lens, our visual search tool. To get started, just open Lens in the Google app, tap the Live icon, and ask whatever’s on your mind while pointing your camera. You can have a free-flowing, back-and-forth conversation with Search in AI Mode, aided by all the visual context from your live camera feed, like different angles or objects in motion.Search Live with video input is rolling out this week on mobile in the U.S., for users enrolled in the AI Mode Labs experiment.Search what you see while browsingWith Lens in Chrome and AI Mode, you can ask and learn about what’s on your desktop screen — whether that’s a website, a PDF or anything else you’re viewing in the browser. Beginning soon, when you click on the Chrome address bar, you’ll see a new option to “Ask Google about this page” in the dropdown suggestions — another easy way to access Lens in Chrome. Perhaps you’re looking at a geometry problem and want to better understand one of the diagrams. Click on “Ask Google about this page” from the address bar and select the diagram. You’ll get an AI Overview with a snapshot of key information directly in the side panel. And this week, you’ll be able to follow up with more questions through AI Mode, by selecting AI Mode at the top of the Lens search results or by clicking the “Dive deeper” button at the bottom of the AI Overview.These are just some of the ways AI Mode in Search can help you learn and explore information on the web. If you’re interested in more tips for the upcoming school year, like help with back to school shopping, check out these recent updates. POSTED IN: Search AI",2025-07-29 16:00:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-04 04:49:15.919,2025-08-22 05:06:37.527,intermediate,"・画像・PDFへの質問対応とファイルタイプ拡大：AIモードは既にAndroid/iOSアプリで画像への質問に対応していたが、デスクトップブラウザにも展開。今後数週間でPDFアップロードにも対応し、PDF内の詳細な質問にも回答可能になる。さらに、将来的にはGoogleドライブからのファイルにも対応予定で、多様なファイルからの情報活用を促進する。例として、心理学の講義スライドをアップロードし、理解を深めるための質問が可能になる。現在、英語で米国とインドの18歳以上のユーザーが利用可能
・計画作成支援機能「Canvas」：大規模なプロジェクトやタスク管理に役立つ新機能。複数セッションに渡り情報を整理・計画を作成できる動的サイドパネルを提供する。例えば、テストの勉強計画作成をAIモードに依頼し、「Canvas作成」ボタンで開始できる。作成した計画は保存され、必要に応じて修正・追記が可能。今後数週間以内に米国でAIモードLabs実験参加ユーザー向けにデスクトップブラウザで展開予定。ファイルアップロード機能により、授業ノートやシラバスなどの情報を活用したカスタマイズも可能になる
・リアルタイムヘルプ機能「Search Live」：Project Astraの高度な機能をAIモードに統合した機能。カメラで撮影したものをリアルタイムで分析し、複雑な概念を説明する。Google Lensと完全に統合されており、GoogleアプリでLensを開き、Liveアイコンをタップして質問することで利用できる。動画入力による視覚的コンテキストを活用した双方向の会話が可能になる。現在、米国でAIモードLabs実験参加ユーザー向けにモバイルで展開中
・ChromeでのLens統合と「このページについてGoogleに質問」機能：ChromeのLensとAIモードを統合し、デスクトップ画面上のウェブサイトやPDFなどについて質問できる。アドレスバーに「このページについてGoogleに質問」オプションが表示され、簡単にLensにアクセスできるようになる。図表などを選択して質問することで、AIの概要と主要な情報がサイドパネルに表示され、AIモードで詳細な質問を続けることができる
・AIモードの今後の展望：本記事で紹介された機能以外にも、バック・トゥ・スクール関連のショッピング支援など、様々な機能追加が予定されている。AIモードは学習や情報探索を支援する強力なツールとして、今後も進化を続けることが期待される",unified,8
cmdzbmfny000aterdl3n86m4m,Meet your new AI coding teammate: Gemini CLI GitHub Actions,https://blog.google/technology/developers/introducing-gemini-cli-github-actions/,Gemini CLI GitHub Actionsは、Geminiの機能をGitHubワークフローに統合するオープンソースAIエージェントです。Issueの自動分類、Pull Requestのレビュー高速化、オンデマンドでのタスク委任を可能にし、開発効率を向上させます。セキュアな認証、アクセス制御、ログ監視機能も備えています。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CLI_SS.width-1300.png,"In June, we launched Gemini CLI, an open-source AI agent that brings the power of Gemini to your terminal. The enthusiastic adoption from developers has been incredible. To keep up with the flood of feature requests and contributions, we put our own tool to the test — using Gemini CLI to automate issue triage and pull request reviews. When community members noticed our new workflows, they asked us to share what we’ve built.Today, we’re introducing Gemini CLI GitHub Actions. It’s a no-cost, powerful AI coding teammate for your repository. It acts both as an autonomous agent for critical routine coding tasks, and an on-demand collaborator you can quickly delegate work to.It’s now in beta, available to everyone worldwide, and you can find it on GitHub at google-github-actions/run-gemini-cli.An AI teammate in your repositoryWhile Gemini CLI is a tool built for individual use in your own terminal, Gemini CLI GitHub Actions was created for team collaboration on the platform where developers work with each other.Triggered by events like new issues or pull requests, it works asynchronously in the background, using the full context of your project to automatically handle tasks. It knows your code, understands what you want to do, and gets it done.We’re launching with three powerful, open-source workflows that can help you code better, faster:🤖Intelligent issue triage: Automate the overhead of managing new issues. Gemini CLI can analyze, label and prioritize incoming issues, helping focus your attention on what matters most.🚀Accelerated pull request reviews: Get instant, insightful feedback on code changes. Gemini CLI can review pull requests for quality, style and correctness, freeing up reviewers to focus on more complex tasks and decisions.🤝On-demand collaboration: Simply mention @gemini-cli in any issue or pull request to delegate tasks. Tell it to do things like, ""write tests for this bug,"" ""implement the changes suggested above,"" ""brainstorm alternative solutions,"" or ""fix this well defined bug.""Easily create new feature requests on GitHub for Gemini CLI to handle on your behalfGemini CLI GitHub Actions can handle your pull requests, providing code changes and AI-generated suggestions for improving the user experienceDelegate work with an ""@gemini-cli"" tag and the agent can complete a range of tasks, from writing bugs to fixing bugsThink of these initial workflows as your launchpad. They are open-source and fully customizable — you can create your own workflows, or configure the ones that come built into Gemini CLI GitHub Actions.Built with enterprise-grade security and controlRobust security measures are a fundamental part of modern software development. That’s why we built Gemini CLI GitHub Actions with security and flexibility at its core.You are always in control with capabilities including:Secure, credential-less authentication: Vertex AI and Gemini Code Assist Standard and Enterprise users can tap into Google Cloud's Workload Identity Federation (WIF) to eliminate the need for long-lived API keys in your environment, drastically reducing the risk of credential compromise.Granular control: Enforce the principle of least privilege with multi-layered controls. Use capabilities like command allowlisting to explicitly approve every shell command the agent can execute. You can also create a custom identity for the agent (e.g., gemini-for-your-org) and grant it only the precise permissions it needs.Complete transparency: GitHub on CLI comes integrated with OpenTelemetry, an industry standard for telemetry, so you can stream logs and metrics to your preferred observability platform, like Google Cloud Monitoring. This gives you full, real-time visibility into every action to monitor usage and debug complex workflows.Get started todayWhat will you build with your new coding teammate? A workflow that automatically generates release notes? One that keeps documentation in sync with your code? Don’t just imagine it; build it. We invite you to contribute your innovative workflows to our repository and share them with the community.Gemini CLI GitHub Actions is available today in beta, with generous free-of-charge quotas for Google AI Studio. Vertex AI, along with the Standard and Enterprise tiers of Gemini Code Assist, are also supported. We will have free-of-charge use for Gemini Code Assist for individual users available soon.To get started, download Gemini CLI 0.1.18 or later and run `/setup-github`. You can find the GitHub Action at google-github-actions/run-gemini-cli.",2025-08-06 01:00:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-06 02:00:19.15,2025-08-22 05:06:37.836,beginner,"・AIによるIssue自動分類：Gemini CLIは、新規Issueを分析し、自動的にラベル付け、優先順位付けを行います。これにより、開発者は重要なIssueに集中でき、作業効率が向上します。例えば、「バグ修正依頼」や「機能追加要望」といったラベルを自動付与し、優先度を「高」「中」「低」に分類することで、開発チームのタスク管理を効率化します。この機能は、大量のIssueに悩まされているプロジェクトにとって特に有効です
・Pull Requestの高速レビュー：Gemini CLIは、Pull Requestのコード変更をレビューし、品質、スタイル、正確性に関するフィードバックを即座に提供します。レビュー担当者は、より複雑なタスクや意思決定に集中できます。具体的には、コードスタイルの違反や潜在的なバグを検出し、修正案を提案することで、レビュー時間を短縮し、コード品質の向上に貢献します。また、レビューコメントの自動生成も可能で、レビュー担当者の負担を軽減します
・オンデマンドコラボレーション：IssueやPull Requestで`@gemini-cli`をメンションすることで、Gemini CLIにタスクを委任できます。「このバグのテストを書く」「上記の変更を実装する」「代替案を提案する」「このバグを修正する」など、様々な指示に対応します。これにより、開発者はより創造的な作業に集中でき、チーム全体の生産性を向上させます。例えば、複雑なロジックの修正を依頼したり、新しい機能のアイデアを生成するといった高度なタスクにも対応可能です
・エンタープライズグレードのセキュリティ：Gemini CLI GitHub Actionsは、セキュアな認証（Workload Identity Federation）、アクセス制御（コマンド許可リスト、カスタムID）、完全な透明性（OpenTelemetryによるログ監視）を備えています。これにより、機密情報の漏洩リスクを最小限に抑え、安全にAIを活用できます。具体的には、APIキーを使用せずにGoogle Cloudの認証システムと連携することで、セキュリティリスクを軽減します。また、実行可能なコマンドを制限することで、不正な操作を防止します
・カスタマイズ可能なワークフロー：提供されているワークフローはオープンソースで、自由にカスタマイズ可能です。独自のワークフローを作成したり、既存のワークフローを調整して、プロジェクトのニーズに合わせて最適化できます。例えば、特定のコードスタイルに合わせたレビュールールを作成したり、特定のイベントにトリガーされる独自のタスクを作成することができます。これにより、Gemini CLI GitHub Actionsを様々なプロジェクトで柔軟に活用できます",unified,8
cmdwms0hf0051te687jbaz54q,We’re improving Ask Photos and bringing it to more Google Photos users.,https://blog.google/products/photos/updates-ask-photos-search/,Googleフォトの「Ask Photos」機能が改善され、米国のユーザーへの展開が拡大する。Geminiモデルを活用し、複雑な検索クエリに対応する一方、シンプルな検索では従来の検索機能を統合し、高速化を実現した。これにより、シンプルかつ複雑な検索を1つのインターフェースで効率的に行えるようになった。,https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/wagtailvideo-mbcag8qi_thumb.jpg,"The Keyword Home Product news Product news Android, Chrome & Play Android Chrome Chromebooks Google Play Wear OS See all Platforms & Devices Fitbit Google Nest Pixel See all Explore & Get Answers Gemini Maps News Search Shopping See all Connect & Communicate Classroom Photos Registry Translate In the Cloud Google Workspace More on the Cloud Blog Google Cloud See all See all product updates Company news Company news Outreach & initiatives Arts & Culture Education Entrepreneurs Public Policy Sustainability See all Technology AI Developers Health Google DeepMind Google Labs Safety and security See all Inside Google Data centers and infrastructure Doodles Googlers Life at Google See all Around the globe Google in Asia Google in Europe Google in Latin America See all Authors Sundar Pichai, CEO Demis Hassabis, CEO and Co-Founder, Google DeepMind Kent Walker, SVP James Manyika, SVP Ruth Porat, President & Chief Investment Officer See all Feed Press corner RSS feed Subscribe Breadcrumb Products Google Photos We love seeing how you’re using Ask Photos in early access, like asking ""suggest photos that'd make great phone backgrounds"" or ""what did I eat on my trip to Barcelona?"" Ask Photos uses Gemini models to answer complex queries like these, but we’ve also heard your feedback that it should return more photos faster for simple searches, like “beach” or “dogs.”To address this, we're bringing the best of Photos' classic search feature into Ask Photos and improving latency, so you can get fast help with simple and complex queries in one place. You’ll now see results right away while Gemini models continue to work in the background to find the most relevant photos or information for more complex queries.With these improvements, Ask Photos is opening up beyond early access and starting to roll out to more eligible users in the U.S. Keep the feedback coming! POSTED IN: Photos AI Related stories Let’s stay in touch. Get the latest news from Google in your inbox. Subscribe No thanks",2025-06-26 17:00:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-04 04:49:16.659,2025-08-22 05:06:37.528,intermediate,"・Ask Photos機能の改善と展開拡大：Googleフォトの「Ask Photos」機能は、Geminiモデルを用いた複雑な画像検索を可能にする。初期アクセスでは、「最高のスマホ壁紙になりそうな写真を選んで」や「バルセロナ旅行で何を食べたか」といった複雑なクエリに対応していたが、ユーザーフィードバックに基づき、シンプルな検索（例：「ビーチ」「犬」）の高速化が図られた。これにより、シンプルな検索は従来の高速な検索機能が優先的に使用され、複雑な検索はバックグラウンドでGeminiモデルが処理を行うため、ユーザーは迅速に結果を得られるようになった。この改善により、Ask Photosは初期アクセスから脱却し、米国のより多くのユーザーに展開されることになった
・Geminiモデルの活用と検索性能向上：Ask Photosは、GoogleのAIモデルであるGeminiを活用することで、複雑な画像検索クエリにも対応できる。例えば、「最高のスマホ壁紙になりそうな写真を選んで」といった、画像の内容理解とユーザーの意図を推測する必要があるクエリにも対応可能である。従来の検索機能とGeminiモデルの併用により、シンプルな検索は高速に、複雑な検索は高精度に処理されるようになり、検索性能が大幅に向上した。これにより、ユーザーはより効率的に目的の写真を見つけられるようになった
・ユーザーフィードバックに基づく改善：Googleはユーザーからのフィードバックを積極的に取り入れ、Ask Photosの改善に役立てている。初期アクセス段階でのユーザーからの要望や不満を分析し、シンプルな検索の高速化という重要な改善点に繋げている。このユーザー中心のアプローチは、製品の品質向上に大きく貢献している。継続的なフィードバックの収集と反映により、Ask Photosはさらに進化していくことが期待される
・今後の展望と展開：Ask Photosは、米国での展開拡大を皮切りに、今後世界各国への展開も期待される。Googleは、ユーザーからのフィードバックを継続的に収集し、機能の改善を続けることで、Ask Photosをより便利で使いやすいサービスへと進化させていく計画である。将来的には、より高度な画像認識技術やAI機能が追加され、ユーザーエクスペリエンスの向上に繋がる可能性がある",unified,8
cmdwms09k0032te6812vv7al1,Try featured notebooks on selected topics in NotebookLM,https://blog.google/technology/google-labs/notebooklm-featured-notebooks/,NotebookLMに専門家作成の特集ノートブック機能が追加された。科学、旅行、経済予測など多様なトピックを網羅し、ソース資料の閲覧、質疑応答、深掘り学習が可能。公開共有機能も利用でき、コミュニティでの知識共有を促進する。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Try_featured_notebooks_on_selected_topics_in_.width-1300.png,"Breadcrumb Technology Google Labs Try featured notebooks on selected topics in NotebookLM Jul 14, 2025 · Share Twitter Facebook LinkedIn Mail Copy link From science to Shakespeare, get advice from experts and call upon curated collections of information with featured notebooks in NotebookLM, available today. Steven Johnson Editorial Director, Google Labs Read AI-generated summary General summary NotebookLM now features notebooks from experts to help you explore topics. You can read source material ask questions and explore topics in depth. Also you can share notebooks publicly with the community. Summaries were generated by Google AI. Generative AI is experimental. Basic explainer NotebookLM has a cool new feature. Now, it has special notebooks made by experts like authors and scientists. These notebooks cover all sorts of topics, like travel and science. You can ask questions and learn a lot from them. Summaries were generated by Google AI. Generative AI is experimental. Explore other styles: General summary Basic explainer Share Twitter Facebook LinkedIn Mail Copy link One of the secrets to getting the most out of NotebookLM is assembling high-quality sources to help you explore your interests. Today, we’re rolling out a new feature making that easier than ever. We’re working with respected authors, researchers, publications and nonprofits around the world to create featured notebooks.The notebooks cover everything from in-depth scientific explorations to practical travel guides to advice from experts. Our initial lineup includes:Longevity advice from Eric Topol, bestselling author of “Super Agers”Expert analysis and predictions for the year 2025 as shared in The World Ahead annual report by The EconomistAn advice notebook based on bestselling author Arthur C. Brooks' ""How to Build A Life"" columns in The AtlanticA science fan’s guide to visiting Yellowstone National Park, complete with geological explanations and biodiversity insightsAn overview of long-term trends in human wellbeing published by the University of Oxford-affiliated project, Our World In DataScience-backed parenting advice based on psychology professor Jacqueline Nesi’s popular Substack newsletter, Techno SapiensThe Complete Works of William Shakespeare, for students and scholars to exploreA notebook tracking the Q1 earnings reports from the top 50 public companies worldwide, for financial analysts and market watchers alike Each collection lets you explore the content using all of NotebookLM's signature features. You can read the original source material, but you can also pose questions or explore specific topics in depth, and get answers grounded in the original material, with citations. You can listen to pre-generated Audio Overviews, or explore the main themes using our Mind Maps feature.A new way to share notebooks — and knowledgeLast month, we introduced the ability to publicly share notebooks. Over the past four weeks, more than 140,000 public notebooks have been created, on a wide range of topics. We'll continue to introduce new featured notebooks, including additional collections from our partnerships with The Economist and The Atlantic.With featured notebooks and public sharing, NotebookLM gives you the ability to explore and share expertise, commentary and public domain information. Featured notebooks will start rolling out to users on desktop today, and we look forward to seeing all the public notebooks created by the NotebookLM community.Here's what two of our partners had to say: POSTED IN: Google Labs AI",2025-07-14 16:05:00,cmdwmplco0001tec833nye4ak,0,60,0,2025-08-04 04:49:16.376,2025-08-22 05:06:38.065,intermediate,"・特集ノートブックの概要：NotebookLMは、専門家（作家、科学者など）が作成した特集ノートブックを提供開始した。テーマは科学、旅行、経済予測など多岐に渡り、各ノートブックは関連する高品質なソース資料に基づいている。Eric Topolの健康長寿に関するアドバイス、The Economistの2025年予測、Arthur C. Brooksの人生論、Yellowstone国立公園ガイドなど、多様な分野の専門知識が提供されている
・NotebookLMの機能強化：特集ノートブックは、NotebookLMの既存機能（ソース資料閲覧、質疑応答、Mind Maps、Audio Overviewsなど）と連携している。ユーザーはオリジナルソースを読み込み、特定のトピックについて質問したり、深く掘り下げて調査したりすることができる。回答はオリジナル資料に基づいており、引用元も明記される。これにより、より効率的で深い学習体験が可能になる
・公開共有機能とコミュニティ：NotebookLMは先月、ノートブックの公開共有機能を導入した。既に14万以上の公開ノートブックが作成されており、活発なコミュニティが形成されつつある。GoogleはThe EconomistやThe Atlanticとの連携を強化し、今後も新たな特集ノートブックを追加していく予定である
・パートナーシップと今後の展望：GoogleはThe Economist、The Atlanticなどの著名な出版社や研究機関と提携し、高品質なノートブックを提供している。これにより、信頼性の高い情報に基づいた学習環境が提供される。公開共有機能と連携することで、ユーザーによる知識創造と共有が促進され、NotebookLMコミュニティの活性化が期待される。今後、さらに多くのパートナーシップを拡大し、ノートブックの質と量の向上を目指していく
・技術的側面：本機能は、AIを活用した情報収集・整理・提示技術に基づいている。具体的には、自然言語処理、知識グラフ、情報検索技術などが活用されていると考えられる。公開共有機能は、ユーザー間の協調的な知識構築を促進する仕組みであり、ソーシャルコンピューティングの要素も含まれる",unified,8
cmdwms08s002ute68fw5kt7xy,A summer of security: empowering cyber defenders with AI,https://blog.google/technology/safety-security/cybersecurity-updates-summer-2025/,Googleは、AIを活用したサイバーセキュリティ強化に向けた最新技術を発表した。AIエージェント「Big Sleep」は実世界の脆弱性を発見し、攻撃を阻止する成果を挙げている。TimesketchへのAI機能追加や、Insider Threat検知システムFACADEの公開も予定。産官学連携によるCoalition for Secure AI (CoSAI)への貢献や、AI Cyber Challenge (AIxCC)への参加を通して、AIによる安全なデジタルエコシステム構築を目指す。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/SocialShare_7.width-1300.jpg,"Breadcrumb Technology Safety & Security A summer of security: empowering cyber defenders with AI Jul 15, 2025 · Share Twitter Facebook LinkedIn Mail Copy link Today we’re sharing more about our latest AI innovations for security, public and private partnerships, and new initiatives to secure the digital ecosystem for everyone. Kent Walker President of Global Affairs, Google & Alphabet Read AI-generated summary General summary AI is improving cybersecurity, so you can expect new tools to help defenders find vulnerabilities faster. Google's Big Sleep agent found real-world security flaws, and new AI capabilities are being added to Timesketch. Also, Google is working with partners to ensure AI systems are secure. Summaries were generated by Google AI. Generative AI is experimental. Share Twitter Facebook LinkedIn Mail Copy link AI provides an unprecedented opportunity for building a new era of American innovation. We can use these new tools to grow the U.S. economy, create jobs, accelerate scientific advances and give the advantage back to security defenders.And when it comes to security opportunities — we’re thrilled to be driving progress in three key areas ahead of the summer’s biggest cybersecurity conferences like Black Hat USA and DEF CON 33: agentic capabilities, next-gen security model and platform advances, and public-private partnerships focused on putting these tools to work. 1. Giving defenders an edge with agentic capabilitiesLast year, we announced Big Sleep, an AI agent developed by Google DeepMind and Google Project Zero, that actively searches and finds unknown security vulnerabilities in software. By November 2024, Big Sleep was able to find its first real-world security vulnerability, showing the immense potential of AI to plug security holes before they impact users.Since then, Big Sleep has continued to discover multiple real-world vulnerabilities, exceeding our expectations and accelerating AI-powered vulnerability research. Most recently, based on intel from Google Threat Intelligence, the Big Sleep agent discovered an SQLite vulnerability (CVE-2025-6965) — a critical security flaw, and one that was known only to threat actors and was at risk of being exploited. Through the combination of threat intelligence and Big Sleep, Google was able to actually predict that a vulnerability was imminently going to be used and we were able to cut it off beforehand. We believe this is the first time an AI agent has been used to directly foil efforts to exploit a vulnerability in the wild.These AI advances don’t just help secure Google's products. Big Sleep is also being deployed to help improve the security of widely used open-source projects — a major win for ensuring faster, more effective security across the internet more broadly. These cybersecurity agents are a game changer, freeing up security teams to focus on high-complexity threats, dramatically scaling their impact and reach.But of course this work needs to be done safely and responsibly. In our latest white paper, we outline our approach to building AI agents in ways that safeguard privacy, mitigate the risks of rogue actions, and ensure the agents operate with the benefit of human oversight and transparency. When deployed according to secure-by-design principles, agents can give defenders an edge like no other tool that came before them.We will continue to share our agentic AI insights and report findings through our industry-standard disclosure process. You can keep tabs on all publicly disclosed vulnerabilities from Big Sleep on our issue tracker page. 2. Announcing new AI security capabilitiesAgentic tools are just one way that AI can help alleviate the pressures put on today’s cybersecurity defenders — particularly when it comes to the grueling task of sifting through large amounts of data to identify incidents. That’s why this summer, we’ll be demoing AI capabilities that give defenders the upper hand.Timesketch: We are extending Timesketch, Google’s open-source collaborative digital forensics platform, with agentic capabilities. Powered by Sec-Gemini, Timesketch will accelerate incident response by using AI to automatically perform the initial forensic investigation. This lets analysts focus their efforts on other tasks, while drastically cutting down on investigation time. At Black Hat USA (booth #2240—come on by!), we’ll demo Timesketch’s new agentic log analysis capabilities, powered by Sec-Gemini, and showcase concrete use cases.FACADE: At Black Hat, we’ll also provide the first live, behind-the-scenes look at FACADE (Fast and Accurate Contextual Anomaly Detection) — an important AI-based system, which has been performing insider threat detection at Google since 2018. Attendees will learn how FACADE processes billions of daily security events across Google to identify internal threats. And thanks to its unique contrastive learning approach, it doesn’t require data from past attacks to do its job.DEF CON GENSEC Capture the Flag (CTF): At DEF CON 33, we’re partnering with Airbus for a CTF event to show how AI can advance cybersecurity professionals’ capabilities. Participants will have the opportunity to team up with an AI assistant to complete challenges designed to engage participants across all skill levels. 3. Putting these tools to work with public and private partnersCollaboration across industry and with public sector partners is essential to cybersecurity success. That’s why we worked with industry partners to launch the Coalition for Secure AI (CoSAI), an initiative to ensure the safe implementation of AI systems. To further this work, today we’re announcing Google will donate data from our Secure AI Framework (SAIF) to help accelerate CoSAI’s agentic AI, cyber defense and software supply chain security workstreams.Additionally, next month at DEF CON 33, the final round of our two-year AI Cyber Challenge (AIxCC) with DARPA will come to a close. Challengers will unveil new AI tools to help find and fix vulnerabilities that can help secure major open-source projects. Be on the lookout for an announcement about the winners from DEF CON 33 next month.We have always believed in AI’s potential to make the world safer, but over the last year we have seen real leaps in its capabilities, with new tools redefining what lasting and durable cybersecurity can look like.This summer’s advances in AI have the potential to be game-changing, but what we do next matters. By building these tools the right way, applying them in new ways and working together with industry and governments to deploy them at scale, we can usher in a digital future that’s not only more prosperous, but also more secure. POSTED IN: Safety & Security AI Public Policy",2025-07-15 10:00:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-04 04:49:16.348,2025-08-22 05:06:38.065,intermediate,"・AIエージェント「Big Sleep」による脆弱性発見と攻撃阻止：Google DeepMindとProject Zeroが開発したAIエージェント「Big Sleep」は、2024年11月以降、複数のリアルワールドの脆弱性を発見している。特に、SQLiteの脆弱性(CVE-2025-6965)を事前に発見し、攻撃を阻止した事例は画期的である。これは、脅威インテリジェンスとBig Sleepの連携による成果であり、AIエージェントが実世界の脆弱性悪用を直接阻止した初めての事例と考えられる。Big Sleepはオープンソースプロジェクトのセキュリティ向上にも貢献しており、セキュリティチームの負担軽減と効率化に大きく寄与する。Googleは、プライバシー保護、不正行為の軽減、人間の監督と透明性を確保する原則に基づき、Big Sleepを安全かつ責任ある方法で展開している
・TimesketchとFACADEによるAIセキュリティ機能強化：Googleのオープンソースデジタルフォレンジックプラットフォーム「Timesketch」に、Sec-Geminiを駆使したAI機能を追加。これにより、インシデント対応の自動化と迅速化を実現する。Black Hat USAでは、この新機能のデモと具体的なユースケースが公開される。また、Google内部で2018年から運用されているInsider Threat検知システム「FACADE」もBlack Hat USAで初公開される。FACADEは、独自のContrastive Learningアプローチにより、過去の攻撃データに依存せず、日々数十億件のセキュリティイベントを処理して内部脅威を特定する
・DEF CON 33でのAI活用デモとCTFイベント：DEF CON 33では、Airbusとの連携でAIを活用したCTFイベントを開催。参加者はAIアシスタントと協力して課題を解決し、様々なスキルレベルの参加者が楽しめる設計となっている。また、DARPAとの共同プロジェクトであるAI Cyber Challenge (AIxCC)の最終ラウンドもDEF CON 33で終了し、新たなAIツールと受賞者が発表される予定である
・Coalition for Secure AI (CoSAI)への貢献：Googleは、AIシステムの安全な実装を促進するCoSAIに、Secure AI Framework (SAIF)からのデータ提供を行うことを発表した。これは、CoSAIのAIエージェント、サイバー防御、ソフトウェアサプライチェーンセキュリティの取り組みを加速させることを目的としている
・AIによるサイバーセキュリティの未来：Googleは、AIが世界をより安全にする可能性を信じている。Big SleepやTimesketch、FACADEなどの最新技術は、サイバーセキュリティの在り方を再定義する可能性を秘めている。これらのツールを適切に構築し、新たな方法で適用し、産業界や政府と協力して大規模に展開することで、より安全で繁栄したデジタル未来を実現できると期待している",unified,8
cme1ixcu8000ite4ausa5qnkt,The latest AI news we announced in July,https://blog.google/technology/ai/google-ai-updates-july-2025/,Googleは7月のAI関連発表をまとめた。AIツールへのアクセス拡大と利便性向上に注力し、検索のAIモード強化、Circle to Search/LensへのAIモード搭載、NotebookLMの機能拡張(ビデオ概要作成、Studioパネル追加)、Googleフォトへのクリエイティブツール追加(写真動画化、スタイル変換)、Veo 3のグローバル展開拡大、AI搭載ショッピング機能の提供、古代文字解読AIモデルAeneasの発表、高解像度地球地図作成AIモデルAlphaEarth Foundationsの公開、米国におけるエネルギー・AIインフラ投資などを発表した。これらのイノベーションは、教育、ゲーム、ショッピング、歴史研究、環境問題など幅広い分野でAIの活用を促進する。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/July_AI_Roundup_ss.width-1300.png,"For more than 20 years, we’ve invested in machine learning and AI research, tools and infrastructure to build products that make everyday life better for more people. Teams across Google are working on ways to unlock AI’s benefits in fields as wide-ranging as healthcare, crisis response and education. To keep you posted on our progress, we're doing a regular roundup of Google's most recent AI news.Here’s a look back at some of our AI announcements from July.In July, we focused heavily on not only expanding access to our AI tools by bringing them to more people and devices, but also making sure those tools are truly useful for all those new people who are gaining access to our latest offerings. Whether seeing the Earth in unprecedented detail with AlphaEarth Foundations, customizing your style with AI shopping tools, or even adding your own creative expressions to your old photos, our latest AI updates are not only more accessible, but built for your experience of the world.We introduced new ways to learn with AI Mode in Search ahead of the school year. AI Mode, our most powerful AI search experience, is now more useful than ever thanks to its latest upgrades. There’s Canvas for planning, Search Live with video, PDF uploads and more. You can use these new features to learn and explore in new ways, whether you’re a student, parent or educator (or just wrapping up a busy summer).We brought AI Mode to Circle to Search and Lens for deeper dives on visual searches. You can now use AI Mode within Circle to Search and Lens to explore complex topics and ask follow-up questions about your visual searches without switching apps. Plus, gamers can now get help while playing mobile games on their Android devices using Circle to Search. Stuck on a level and need some quick tips? Circle to Search will recognize the exact timestamp of your game and show you an AI Overview with information about what’s on your screen, including suggested articles and videos to help you even further navigate your game.We introduced video overviews and an upgraded Studio panel in NotebookLM. Tens of millions of people have used NotebookLM as their personalized AI research assistant to turn complex material into digestible formats like Audio Overviews. Now, you can use NotebookLM to make Video Overviews.Plus, the new Studio panel makes NotebookLM even more powerful and collaborative. You can now create notebooks in multiple formats. So if you’re studying for a big exam, you can create Mind Maps, Study Guides or Video Overviews, each focusing on a different chapter of your course notes.We introduced new creative tools to Google Photos to transform your old pics. The AI tool people have been using in Gemini to turn their photos into videos is now available in Google Photos. The new feature allows you to animate your pictures, or you can try Remix to transform them into styles like anime or 3D art. Plus, a new ""Create"" tab in the Photos app — rolling out first in the U.S. this August — puts all creative tools in one easy spot.We launched photo-to-video and brought Veo 3 to people in more countries. We launched our state-of-the-art video generation model Veo 3 in May — and this month we expanded access to Google AI Pro subscribers in over 150 countries. Now, with a new capability in Gemini, you can now transform your favorite photos into dynamic eight-second video clips with sound.We made it possible for images to talk with Veo 3 in Flow. Since launching in May, people have generated tens of millions of videos in Flow, our AI tool for filmmakers. Using Veo 3, you can add sound effects and background noise to these clips. This latest feature allows you to generate speech as well, and we’re expanding Flow to more countries.We launched a new way to personalize shopping and track prices with AI. Our try on experience that lets you try clothes on yourself is now available in the U.S., allowing you to upload your photo, tap ""try it on” and see how you look in billions of items of clothing on Google. Never miss a deal with our upgraded price alerts, which are rolling out now and let you track your desired price and specific sizes and colors; and our AI-powered outfit and room design will be at your fingertips in AI Mode, with vision match technology that uses AI to generate a range of visual options and highlight similar, shoppable products.We introduced a new AI model to help historians interpret ancient texts. Google DeepMind’s Aeneas is built to help historians interpret, attribute and restore fragmentary ancient texts. Aeneas can search for texts that share similarities in wording, syntax, standardized formulas or provenance across thousands of Latin inscriptions, process multimodal text and images and restore gaps in text. While trained for Latin, Aeneas can be adapted to other ancient languages, scripts and media, from papyri to coinage.We introduced a new AI model to map our planet in unprecedented detail. Our AlphaEarth Foundations AI model functions like a virtual satellite that characterizes the planet’s entire terrestrial land and coastal waters by integrating large amounts of Earth observation data into an embedding that a computer system can easily process. With the Satellite Embedding Dataset, scientists can get a more complete and consistent picture of our planet's evolution, while offering insights on critical issues like food security, deforestation, urban expansion and water resources.We shared our plans to invest in America’s energy, data center infrastructure and AI skills development. At the Pennsylvania Energy & Innovation Summit, Alphabet and Google’s President and Chief Investment Officer Ruth Porat announced a $3 billion deal with Brookfield to modernize two Pennsylvania hydropower facilities; a new AI skills training program for workers and small businesses; and an investment of over $25 billion in data centers and AI infrastructure across the PJM region.We used a new AI agent to stop a cybersecurity vulnerability in the wild. Ahead of this summer’s Aspen Security Forum, Google President of Global Affairs Kent Walker offered a glimpse into how Google is using AI to fight cyber threats in the U.S., including the use of AI to uncover a vulnerability known to attackers and at the risk of being exploited. “We believe this is the first time an AI agent has been used to directly foil efforts to exploit a vulnerability in the wild,” he said.",2025-08-07 14:30:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-07 15:00:18.369,2025-08-22 05:06:38.164,intermediate,"・AIモードの強化と機能追加：検索におけるAIモードに、Canvasによるプランニング機能、Search Liveによる動画検索、PDFアップロード機能などが追加された。これにより、学習や探索方法が大きく進化し、学生、保護者、教育者にとって非常に有用なツールとなった。Circle to SearchとLensにもAIモードが統合され、視覚検索における複雑なトピックの探求やフォローアップ質問がアプリを切り替えることなく可能になった。モバイルゲームでの活用も可能になり、ゲーム内の特定の場面を認識し、関連情報や攻略動画などを提供する
・NotebookLMの機能拡張と利便性向上：数千万人が利用するパーソナルAI研究アシスタントNotebookLMに、ビデオ概要作成機能と新しいStudioパネルが追加された。Studioパネルにより、マインドマップ、スタディガイド、ビデオ概要など、複数のフォーマットでノートを作成できるようになり、共同作業も容易になった。これにより、複雑な情報を消化しやすい形式に変換する機能がさらに強化された
・Googleフォトへのクリエイティブツール追加：Geminiで利用可能だった写真動画化機能がGoogleフォトに追加された。アニメや3Dアートへの変換機能「Remix」も提供され、古い写真を新たな表現で楽しむことができる。さらに、米国では8月から新しい「作成」タブが導入され、全てのクリエイティブツールが1箇所に集約される
・Veo 3のグローバル展開とFlowへの機能追加：5月に発表された高性能ビデオ生成モデルVeo 3が、Google AI Pro加入者向けに150カ国以上に展開された。Geminiとの連携により、写真から8秒間の動画を生成する機能も追加された。FlowにもVeo 3が統合され、音声効果や背景ノイズの追加に加え、音声生成機能も追加された。Flowもより多くの国で利用可能になった
・AI搭載ショッピング機能の提供：米国では、写真アップロードによるバーチャル試着機能が提供開始された。また、価格アラート機能が強化され、希望価格、サイズ、色を指定して追跡できるようになった。さらに、AIを活用したコーディネート提案や部屋のデザイン提案機能もAIモードで提供される予定
・古代文字解読AIモデルAeneasと高解像度地球地図作成AIモデルAlphaEarth Foundations：Google DeepMindが開発したAeneasは、断片的な古代文字の解釈、属性付け、復元を支援する。ラテン語に特化して訓練されているが、他の古代言語にも適応可能。AlphaEarth Foundationsは、地球全体の陸地と沿岸域を詳細にマッピングするAIモデルで、衛星データなどを統合して処理しやすい形式に変換する。食糧安全保障、森林破壊、都市拡大、水資源などの問題に関する洞察を提供する
・AIによるサイバーセキュリティ対策：Googleは、AIエージェントを使用して、実際に発生しているサイバーセキュリティの脆弱性を阻止したと発表した。これは、AIエージェントが野生の脆弱性の悪用を直接阻止した初めての事例であるとされている",unified,8
cmdxpr47q001ntezp8qr0b6kt,How we’re using AI to help track and predict cyclones,https://blog.google/technology/google-deepmind/weather-lab-ai-cyclone-prediction-tracking/,Google DeepMindとGoogle Researchは、AIを活用した革新的なサイクロン予測モデルを開発した。従来の物理シミュレーションとは異なり、高速かつ高精度にサイクロンの経路、規模、強度を予測する。NHCと連携し、リアルタイム予測を公開するWeather Labプラットフォームもローンチ。このモデルは、サイクロンの発生前に複数の可能性を示す「expert mode」も備え、予報精度向上に貢献する。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Hurricane_SS.width-1300.png,"In March, Google DeepMind’s Ferran Alet and Tom Andersson visited the fortress-like headquarters of the National Hurricane Center (NHC) in Miami. The pair recall being impressed by the operations room — where people gathered before a kaleidoscope of screens showing satellite imagery, radar and modeling — and the building’s 10-inch-thick concrete walls, designed to withstand winds up to 130 miles an hour.Even during a category 5 storm, the NHC must continue operating 24/7, issuing warnings and updates to help people prepare for and survive hurricanes — or cyclones and typhoons, as they’re known in other parts of the world. Ferran and Tom were there to share a first look at a new AI-powered experimental cyclone model to help them do just that.Among the experts gathered in a boardroom to preview the model was a leading hurricane specialist who, some years before, had written a paper suggesting cyclone path prediction might have hit its limits. “After our presentation, he told us that our model’s performance was potentially revolutionary,” Tom says. “It was quite an honor.”Now, Google DeepMind and Google Research are giving people outside that boardroom a first peek at the new model, which — unlike traditional forecasting models that simulate the complex physics of the atmosphere on supercomputers — makes predictions about cyclone path, size and intensity at unprecedented speeds. We’re sharing its forecasts with the NHC and launching Weather Lab, a new data and visualization platform hosting its real-time and historical predictions.Our model (shown in blue) accurately predicted the paths of Cyclones Honde and Garance south of Madagascar, and captured the paths of Cyclones Jude and Ivone in the Indian Ocean almost seven days before they formed.Timelier and more accurate forecasts of a storm’s movements and intensity are vital to giving forecasters the information they need to issue watches and warnings for hurricane hazards — and give people on the ground the time they need to evacuate or prepare their homes. But cyclones present a particular dilemma: They are one of the world’s most devastating weather events, and some of the hardest to predict.“With weather generally, small differences and changes in data can result in widely different futures,” Ferran says. “But the extreme conditions of cyclones make them especially hard to simulate. They’re chaotic systems.”Google DeepMind and Google Research had shown some promise in predicting cyclone tracks using historical data in weather models like GenCast, GraphCast and NeuralGCM. But these were designed for general weather, trained on low-resolution historical data and offered poor intensity predictions. Forecasters didn’t fully trust them. So the team began developing their experimental cyclone model to address the gap.“Cyclones are so sparse and intense in terms of wind speed and vorticity that we had to change the way we actually trained our models,” Ferran says. “We now train on both general weather and sparse cyclone-specific data. To do that, rather than diffusion, which works iteratively in steps, we use a new probabilistic model that works in one step by introducing random perturbations during the prediction process, and ultimately produces a selection of 50 possible outcomes for the storm.”According to preliminary internal evaluations, the new experimental cyclone model shows state-of-the-art accuracy for both cyclone track and intensity. It’s skillful at predicting a cyclone’s size as well.The model’s ensemble mean prediction (bold blue line) correctly anticipated Cyclone Alfred’s rapid weakening to tropical storm status and eventual landfall near Brisbane, Australia, seven days later, with a high probability of landfall somewhere along the coast of the state of Queensland.Trusted testers have had access to the model’s forecasts for about two months, providing the team with valuable feedback not just on accuracy, but how usefully they’re presenting the information and additional features that could help in their work.On her own trip to the NHC — she remembers the formidable walls, too — Google Research product manager Olivia Graham sat side-by-side with a forecaster to walk her through the interface. It showed track and intensity predictions for current storms on a global map from the new model — and other Google weather models — along with official models the forecasters currently use for comparison.“The forecaster told me that while this was helpful, a lot of their work involves looking at potential outcomes before a cyclone forms, or in the time of cyclogenesis,” Olivia says. “That actually led to the development of an ‘expert mode’ available to trusted testers where you can explore potential cyclones, grouping small circles on the map, each of which represents a ~2% chance of cyclone formation. This way you can see its potential track and strength should it form.”That kind of close collaboration is key. “We’re really co-developing this technology with the people at the NHC who will be using it every day — asking what’s the most important data to them and how they want to use it,” Olivia says. “People in the path of danger depend on it, and we want to ensure we’re providing the best and most relevant information to help them save lives.”",2025-08-04 19:00:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-04 23:00:19.863,2025-08-22 05:06:38.118,intermediate,"・AIサイクロン予測モデルの概要：Google DeepMindとGoogle Researchが開発したAIモデルは、従来の物理ベースのモデルとは異なり、機械学習を用いてサイクロンの経路、強度、規模を高速かつ高精度に予測する。これは、大量の気象データと、サイクロン特有の希少かつ高密度なデータを用いた独自の学習方法による。従来モデルでは困難だったサイクロン発生前の予測や、強度の変化予測にも高い精度を示す
・モデルの精度と信頼性：予備的な内部評価では、サイクロンの経路と強度の予測において、最先端の精度を示すことが確認されている。例えば、サイクロンAlfredの弱体化とオーストラリアへの上陸を7日前に高確率で予測した。NHCの専門家からも、その精度の高さは「革命的」と評価されている。2ヶ月間のテスト運用で、予報精度だけでなく、情報提示方法や追加機能についても貴重なフィードバックを得ている
・Weather Labプラットフォーム：リアルタイムおよび過去のサイクロン予測をホストするデータと可視化プラットフォームであるWeather Labをローンチした。これにより、NHCだけでなく、世界中の気象機関や研究者もこのモデルの予測データにアクセスできるようになる。プラットフォームは、予測結果を分かりやすく表示し、予報官の意思決定を支援する設計となっている
・予測方法と技術的特徴：従来の拡散モデルではなく、予測プロセス中にランダムな摂動を導入する新しい確率モデルを採用している。これにより、1ステップで50個の可能な結果を生成し、不確実性を考慮した予測を提供する。これは、サイクロンの複雑さと不確実性を扱うために開発された独自の技術である。モデルは、GenCast、GraphCast、NeuralGCMなどの既存の気象モデルとは異なり、サイクロン特有のデータに特化して訓練されている
・NHCとの連携と今後の展望：NHCの予報官と緊密に協力し、モデルの開発と改良を進めている。予報官のニーズを直接聞き取り、ユーザーインターフェースや機能を改善している。特に、サイクロン発生前の可能性を評価する「expert mode」は、予報官からのフィードバックに基づいて開発された機能である。このモデルは、人命救助に貢献することを目指し、継続的に改善・発展させていく
・モデルの具体的な予測事例：モデルは、マダガスカル南部のサイクロンHondeとGaranceの経路を正確に予測し、インド洋のサイクロンJudeとIvoneの経路を発生7日前から予測した。これらの成功事例は、モデルの予測能力の高さを示している
・データ活用とモデルの拡張性：モデルは、衛星画像、レーダーデータ、その他の気象データなどを統合して訓練されている。将来的には、より高解像度のデータや、他の気象現象に関するデータも活用することで、モデルの精度と予測範囲をさらに拡大していく予定である",unified,8
cmebbew8o000wtej00dzyin9u,Google is investing in infrastructure and an AI-ready workforce in Oklahoma.,https://blog.google/inside-google/company-announcements/google-american-innovation-oklahoma/,Googleは今後2年間でオクラホマ州にクラウドとAIインフラに90億ドルを追加投資する。この投資は、新たなデータセンターの建設と、AI関連の労働力の育成を支援する。オクラホマ州の経済成長と技術発展に大きく貢献するだろう。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/InvestinginOklahoma_SS.max-600x600.format-webp.webp,"<img src=""https://storage.googleapis.com/gweb-uniblog-publish-prod/images/InvestinginOklahoma_SS.max-600x600.format-webp.webp"">Google is investing an additional $9 billion in Oklahoma within the next two years in cloud and AI infrastructure. This investment supports the development of a new data…",2025-08-13 20:05:00,cmdwmplco0001tec833nye4ak,0,64,0,2025-08-14 11:27:41.496,2025-08-22 05:06:38.164,intermediate,"・大規模投資：Googleはオクラホマ州に今後2年間で90億ドルを投資すると発表した。この投資は、同州におけるクラウドコンピューティングと人工知能（AI）インフラの強化を目的としている。これは、Googleのデータセンター拡張計画の一環であり、同州の経済活性化に大きく貢献すると期待されている。
・データセンター建設：投資額の大部分は、オクラホマ州における新たな大規模データセンターの建設に充てられる見込みである。これらのデータセンターは、GoogleのクラウドサービスであるGoogle Cloud Platform（GCP）を支える重要なインフラとなる。高性能コンピューティングリソースの提供により、企業や研究機関のAI開発を加速させる役割を果たすだろう。
・AI人材育成：Googleは、オクラホマ州におけるAI関連の労働力育成にも投資する計画だ。具体的には、教育機関との連携強化や、AI関連のスキル向上プログラムの提供などが考えられる。これにより、オクラホマ州の技術人材の育成を促進し、AI分野における競争力の向上に繋がるだろう。  Googleは、この投資を通じて、オクラホマ州を重要な技術ハブとして発展させることを目指している。",unified,8
cmdwms065002cte682oqx5ggh,More advanced AI capabilities are coming to Search,https://blog.google/products/search/deep-search-business-calling-google-search/,Googleは、Gemini 2.5 ProとDeep Searchを含む高度なAI機能をSearchに追加する。Google AI ProとAI Ultraのサブスクライバーは、複雑なクエリや詳細な調査のためにAIモードで先行アクセスできる。さらに、AIによるローカルビジネスへの価格と在庫確認の電話機能も追加され、時間を節約できる。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/July-AIM-Moment_Hero.width-1300.png,"Breadcrumb Products Search More advanced AI capabilities are coming to Search Jul 16, 2025 · Share Twitter Facebook LinkedIn Mail Copy link We’re rolling out powerful new capabilities in Search, including Gemini 2.5 Pro and Deep Search, to Google AI Pro and AI Ultra subscribers. Robby Stein VP of Product, Google Search Read AI-generated summary General summary Google is adding more advanced AI features to Search using the latest Gemini models. Google AI Pro and AI Ultra subscribers get early access to Gemini 2.5 Pro and Deep Search in AI Mode for complex queries and in-depth research. Also, Search can now use AI to call local businesses for pricing and availability, saving you time. Summaries were generated by Google AI. Generative AI is experimental. Share Twitter Facebook LinkedIn Mail Copy link At I/O, we shared how our latest Gemini models are enabling dramatically more powerful capabilities and features in Search. Now, we’re beginning to roll out access to the Gemini 2.5 Pro model and Deep Search in AI Mode, available for Google AI Pro and AI Ultra subscribers – and introducing a new agentic feature to help you get even more done. Making the most powerful Gemini models available in AI Mode in SearchStarting today, we’re bringing Gemini 2.5 Pro to AI Mode, giving you access to our most intelligent AI model, right in Search. Gemini 2.5 Pro excels at advanced reasoning, math and coding questions, helping you with your complex queries with links to learn more. Subscribers can select the 2.5 Pro model from a drop-down menu in the AI Mode tab. The default model in AI Mode will continue to be helpful for fast, all-around assistance on most questions. For questions where you want an even more thorough response, we’re bringing deep research capabilities into AI Mode through Deep Search with the Gemini 2.5 Pro model. Deep Search is our most advanced research tool in Google Search, helping you save hours by issuing hundreds of searches, reasoning across disparate pieces of information and crafting a comprehensive, fully-cited report in minutes. Deep Search is especially useful for in-depth research related to your job, hobbies, or studies. It's also a valuable tool when making big life decisions, like purchasing a new house or needing assistance with financial analysis. For Google AI Pro and AI Ultra subscribers in the U.S., Deep Search and Gemini 2.5 Pro are starting to roll out this week for those opted into the AI Mode experiment in Labs, where we test our most cutting edge capabilities. Using AI to get things done fasterTo help you get even more done, we’re now bringing a new, agentic capability directly into Search: AI-powered calling to local businesses. From pet grooming to dry cleaning needs, Search can now call businesses to get pricing and availability information on your behalf — without you needing to pick up the phone.To get started, search for something like “pet groomers near me” and you’ll see a new option in the results to “Have AI check pricing.” From there, you can submit your request and Search will do the rest, consolidating information about appointments and services from different businesses to present you with a range of options – saving you time and creating new opportunities for businesses to easily book customers. This capability is now starting to roll out to all Search users in the U.S., with higher limits for Google AI Pro and AI Ultra subscribers. With this new experience, businesses are always in control via their Business Profile settings. Read more here.As we continue to build a more intelligent Search with our most advanced models, we’ll bring some of our most cutting edge AI features to Google AI Pro and AI Ultra subscribers first, providing early access to the forefront of our research and capabilities. And we look forward to continuing to bring advanced capabilities in Search to all our users globally. POSTED IN: Search AI Google One",2025-07-16 16:00:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-04 04:49:16.254,2025-08-22 05:06:38.164,intermediate,"・Gemini 2.5 Proの導入：AIモードにGoogleの最先端AIモデルであるGemini 2.5 Proが導入された。高度な推論、数学、コーディングの質問に優れており、複雑なクエリへの対応と関連情報のリンク提供を実現する。AIモードのデフォルトモデルは引き続き一般的な質問への迅速な対応に役立つが、より詳細な回答が必要な場合はGemini 2.5 Proを選択できる。2025年7月16日より、AIモード実験に参加している米国ユーザーへのロールアウトを開始
・Deep Searchの提供：Gemini 2.5 Proモデルと連携したDeep SearchがAIモードに追加された。これはGoogle Searchで最も高度な調査ツールであり、数百回の検索を行い、様々な情報を関連付けて包括的なレポートを作成することで、時間を大幅に節約できる。仕事、趣味、学習、住宅購入などの大きな意思決定に役立つ。米国Google AI ProおよびAI Ultraサブスクライバー向けに、2025年7月16日よりロールアウト開始
・AIによるローカルビジネスへの電話機能：AIがユーザーに代わってローカルビジネスに電話をかけ、価格や在庫状況を確認する機能が追加された。ペットグルーミングやクリーニングなどの検索で、「AIで価格を確認」オプションが表示され、リクエストを送信すると、様々なビジネスからの情報をまとめて提示する。米国全ユーザーへのロールアウトを開始し、Google AI ProおよびAI Ultraサブスクライバーはより高い利用上限が設定される。ビジネスはBusiness Profile設定で常に制御できる
・Google AI ProとAI Ultraサブスクライバーへの優先提供：Googleは、最も高度なモデルを用いたよりインテリジェントな検索を構築する中で、最も先進的なAI機能をGoogle AI ProとAI Ultraのサブスクライバーに優先的に提供し、研究と機能の最先端への早期アクセスを提供する
・今後の展望：Googleは、高度な機能を世界中のすべてのユーザーに提供していくことを目指している",unified,8
cmdwmrzzs001dte68hkmwlijv,"Try on styles with AI, jump on great prices and more",https://blog.google/products/shopping/back-to-school-ai-updates-try-on-price-alerts/,GoogleはAIを活用した新たなショッピングツールを発表した。AIによるバーチャル試着機能、サイズ・色・価格を指定できる価格アラート機能、AI Modeによるコーディネート・部屋のレイアウト提案機能を提供する。これらの機能により、ユーザーは最適な商品を見つけ、スタイルを簡単に探求できるようになる。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Shopping_Hero_BTS.width-1300.png,"Breadcrumb Products Shopping Try on styles with AI, jump on great prices and more Jul 24, 2025 · Share Twitter Facebook LinkedIn Mail Copy link Google’s shopping tools can help you with everything from trying on the latest trends to redesigning your space — and finding everything at the right price. Danielle Buckley Director of Product, Consumer Shopping Read AI-generated summary General summary Google is launching a virtual try-on tool in the U.S. so you can use AI to see how clothes look on you. Price alerts are also upgraded, letting you specify your preferred size, color and price. Coming this fall, you can explore shoppable outfit and room inspiration from AI Mode using visual matches. Summaries were generated by Google AI. Generative AI is experimental. Bullet points Google's shopping tools help you explore your style and find great prices on clothes and home goods. Use AI to virtually ""try on"" clothes by uploading a photo of yourself to see how they look. Set price alerts specifying your preferred size, color, and price to snag deals. This fall, get outfit and room design inspiration using AI, with shoppable visual matches. These new features make it easier to find the perfect items and style your looks. Summaries were generated by Google AI. Generative AI is experimental. Basic explainer Google has new shopping tools to help you find cool stuff. You can now virtually try on clothes using a photo of yourself. Plus, you can set price alerts for things you want. This fall, Google will also show you outfit and room ideas to help you find things you like. Summaries were generated by Google AI. Generative AI is experimental. Explore other styles: General summary Bullet points Basic explainer Share Twitter Facebook LinkedIn Mail Copy link Whether you’re still on the hunt for the perfect summer maxi skirt, dreaming about a new fall jacket or starting your back to school shopping, our shopping tools can help you explore your personal style and get a good price. Here are a few ways you can use Google’s latest shopping features:Try clothes on, virtuallyAt I/O in May, we introduced our try on tool as a limited experiment in Search Labs, allowing shoppers to upload a photo of themselves and use AI to virtually try on clothes. Today, try on is launching in the U.S., letting you easily try on styles from the billions of apparel items in our Shopping Graph across Search, Google Shopping and even product results on Google Images. To get started, tap on any product listing across Google or any apparel product result on Google Images and tap the “try it on” icon. Upload a full-length photo of yourself and within moments you’ll see what you might look like wearing those gingham-print pants on the first day of class. You can scroll through other looks you’ve tried, save your faves and share with friends.Buy when the price is rightWe’ve also upgraded our price alerts so it’s easier to grab the perfect item as soon as it falls into your budget. Starting to roll out today, when U.S. shoppers hit “track price” to set an alert for a product, you can specify your preferred size and color, as well as the price you want to pay. The Shopping Graph has products and prices from all across the web — so we’ll let you know when there’s an offer that meets your criteria. No more constantly checking to see if that bag you’re eyeing is finally at the right price for you or forgetting to come back to a product you loved! Bring outfit and room design inspo to lifeFinding ways to style the season’s hot trends or looking for fresh decor ideas is getting even easier with the help of AI. Starting this fall in the U.S., you will be able to explore shoppable outfit and room inspiration right from AI Mode — whether you’re looking for style inspo for a green flowy dress for a garden party or design ideas for a bedroom. Our vision match technology will generate a range of visual options for your query and use the 50 billion products in the Shopping Graph to show product listings for visual matches we think you’ll like. You can try this when it's live in the fall — and start looking out for try on and price alerts when you’re shopping across Google. POSTED IN: Shopping Search AI",2025-07-24 16:00:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-04 04:49:16.025,2025-08-22 05:06:38.307,intermediate,"・AIによるバーチャル試着機能：ユーザーは自身の全身写真をアップロードすることで、AIが服の試着をシミュレーションする。Google検索、Googleショッピング、Google画像検索上の衣料品に「試着」アイコンが表示され、対応する商品を試着可能。試着したスタイルは保存・共有もできる。米国で展開開始
・高度な価格アラート機能：価格アラート設定時に、サイズ、色、希望価格を指定できるようになった。Shopping Graph上の膨大な商品情報から、指定条件に合致する価格になった際に通知を受け取れる。常に価格をチェックする必要がなくなり、希望の商品を逃す心配が減る。米国で展開開始
・AI Modeによるコーディネート・部屋のレイアウト提案：秋に米国で開始予定。AI Modeでコーディネートや部屋のレイアウトのインスピレーションを得られる。ビジョンマッチ技術を用いて、クエリに基づいた様々な視覚的なオプションと、Shopping Graph上の500億個の商品からマッチする商品リストを表示する
・Shopping Graphの活用：全ての機能はGoogleのShopping Graphを活用している。Shopping Graphはウェブ上の膨大な商品情報と価格情報を網羅しており、これらの機能の精度と網羅性を高めている
・今後の展望：これらの新機能は、ユーザーのショッピング体験を向上させ、よりパーソナライズされたショッピングを可能にする。Googleは今後もAI技術を活用し、ショッピング体験の改善に努めていくと予想される",unified,8
cme26i7b2003ote8rnv8lgcrj,"The AI model Perch, updated today, uses audio to help protect endangered species.",https://blog.google/technology/google-deepmind/perch-ai-model/,Google DeepMindがAIモデルPerchをアップデート。生物音響データ分析を高度化し、絶滅危惧種の保護に貢献する。幅広い動物種に対応し、効率的なデータ処理を実現。Kaggleで公開されたオープンモデルで、科学者の現場作業を支援する。,https://storage.googleapis.com/gweb-uniblog-publish-prod/images/bioacoustics_16x9_conform_250804a_01456.max-1440x810.jpg,"Google DeepMind released a new version of their AI model Perch, which helps conservationists analyze bioacoustic data from diverse ecosystems This update is generalized to a wider range of animals, so it can analyze audio from Hawaiian honeycreepers to coral reefs. Scientists use microphones and underwater hydrophones to collect audio dense with animal vocalizations, but making sense of so much data is a massive undertaking. This new version of Perch, which is an open model available on Kaggle, is helping scientists protect endangered species by helping them process that data, so scientists can focus their efforts on on-the-ground work.Learn more about Perch on the Google DeepMind blog.",2025-08-07 15:34:00,cmdwmplco0001tec833nye4ak,0,55,0,2025-08-08 02:00:22.143,2025-08-22 05:06:38.4,intermediate,"・AIモデルPerchの概要：Google DeepMindが開発したPerchは、生物音響データ分析を支援するAIモデルです。以前のバージョンから大幅に改良され、ハワイミツスイからサンゴ礁まで、より幅広い動物種の音声データに対応できるようになりました。これは、絶滅危惧種の保護活動において、貴重なツールとなるでしょう
・データ処理の効率化：従来、動物の鳴き声を含む大量の音声データの分析は、膨大な時間と労力を要していました。Perchは、このデータ処理を自動化・効率化することで、科学者たちが分析に費やす時間を大幅に削減し、より多くの時間を現場での保護活動に充てることを可能にします
・オープンソースモデルとしての利点：PerchはKaggleで公開されているオープンソースモデルです。そのため、世界中の研究者や保全活動家が自由に利用でき、共同研究や技術開発を促進することができます。これは、絶滅危惧種の保護に向けたグローバルな取り組みを加速させる上で重要な要素となります。  Perchの利用により、より多くのデータが分析され、絶滅危惧種の保護活動に役立つ知見が得られると期待されます",unified,8
